{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explores the efficiency of Deep Q-Network Agent in a PACMAN Environment. All the dependencies required to run this .ipynb file are present in the code itself."
      ],
      "metadata": {
        "id": "127buel33zdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n",
        "This part contains the code for all the helper fucntions that will be used in the further developement of models.\n",
        "\n"
      ],
      "metadata": {
        "id": "l-xJ8OBtAl9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is written by @sracaniere from DeepMind\n",
        "#https://github.com/sracaniere\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "STANDARD_MAP = np.array([\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "\n",
        "\n",
        "def get_random_position(map_array):\n",
        "  \"\"\"Gets a random available position in a binary map array.\n",
        "\n",
        "  Args:\n",
        "    map_array: numpy array of the map to search an available position on.\n",
        "\n",
        "  Returns:\n",
        "    The chosen random position.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if there is no available space in the map.\n",
        "  \"\"\"\n",
        "  if map_array.sum() <= 0:\n",
        "    raise ValueError(\"There is no available space in the map.\")\n",
        "  map_dims = len(map_array.shape)\n",
        "  pos = np.zeros(map_dims, dtype=np.int32)\n",
        "  while True:\n",
        "    result = map_array\n",
        "    for i in range(map_dims):\n",
        "      pos[i] = np.random.randint(map_array.shape[i])\n",
        "      result = result[pos[i]]\n",
        "    if result == 0:\n",
        "      break\n",
        "  return pos\n",
        "\n",
        "\n",
        "def update_2d_pos(array_map, pos, action, pos_result):\n",
        "  posv = array_map[pos[0]][pos[1]][action - 1]\n",
        "  pos_result[0] = posv[0]\n",
        "  pos_result[1] = posv[1]\n",
        "  return pos_result\n",
        "\n",
        "\n",
        "def parse_map(map_array):\n",
        "  \"\"\"Parses a map when there are actions: stay, right, up, left, down.\n",
        "\n",
        "  Args:\n",
        "    map_array: 2D numpy array that contains the map.\n",
        "\n",
        "  Returns:\n",
        "    A 3D numpy array (height, width, actions) that contains the resulting state\n",
        "    for a given position + action, and a 2D numpy array (height, width) with the\n",
        "    walls of the map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if the map does not contain only zeros and ones.\n",
        "  \"\"\"\n",
        "  act_def = [[0, 0], [0, 1], [-1, 0], [0, -1], [1, 0]]\n",
        "  walls = np.zeros_like(map_array)\n",
        "  new_map_array = []\n",
        "  for i in range(map_array.shape[0]):\n",
        "    new_map_array.append([])\n",
        "    for j in range(map_array.shape[1]):\n",
        "      new_map_array[i].append([])\n",
        "      if map_array[i, j] == 0:\n",
        "        for k in range(len(act_def)):\n",
        "          new_map_array[i][j].append([i + act_def[k][0], j + act_def[k][1]])\n",
        "      elif map_array[i, j] == 1:\n",
        "        for k in range(len(act_def)):\n",
        "          new_map_array[i][j].append([i, j])\n",
        "        walls[i, j] = 1\n",
        "      else:\n",
        "        raise ValueError(\"Option not understood, %d\" % map_array[i, j])\n",
        "      for k in range(len(new_map_array[i][j])):\n",
        "        if map_array[new_map_array[i][j][k][0]][new_map_array[i][j][k][1]] == 1:\n",
        "          new_map_array[i][j][k][0] = i\n",
        "          new_map_array[i][j][k][1] = j\n",
        "  return np.array(new_map_array), walls\n",
        "\n",
        "\n",
        "def observation_as_rgb(obs):\n",
        "  \"\"\"Reduces the 6 channels of `obs` to 3 RGB.\n",
        "\n",
        "  Args:\n",
        "    obs: the observation as a numpy array.\n",
        "\n",
        "  Returns:\n",
        "    An RGB image in the form of a numpy array, with values between 0 and 1.\n",
        "  \"\"\"\n",
        "  height = obs.shape[0]\n",
        "  width = obs.shape[1]\n",
        "  rgb = np.zeros((height, width, 3), dtype=np.float32)\n",
        "  for x in range(height):\n",
        "    for y in range(width):\n",
        "      if obs[x, y, PillEater.PILLMAN] == 1:\n",
        "        rgb[x, y] = [0, 1, 0]\n",
        "      elif obs[x, y, PillEater.GHOSTS] > 0. or obs[x, y, PillEater.GHOSTS_EDIBLE] > 0.:\n",
        "        g = obs[x, y, PillEater.GHOSTS]\n",
        "        ge = obs[x, y, PillEater.GHOSTS_EDIBLE]\n",
        "        rgb[x, y] = [g + ge, ge, 0]\n",
        "      elif obs[x, y, PillEater.PILL] == 1:\n",
        "        rgb[x, y] = [0, 1, 1]\n",
        "      elif obs[x, y, PillEater.FOOD] == 1:\n",
        "        rgb[x, y] = [0, 0, 1]\n",
        "      elif obs[x, y, PillEater.WALLS] == 1:\n",
        "        rgb[x, y] = [1, 1, 1]\n",
        "  return rgb\n",
        "\n",
        "\n",
        "class PillEater(object):\n",
        "\n",
        "  WALLS = 0\n",
        "  FOOD = 1\n",
        "  PILLMAN = 2\n",
        "  GHOSTS = 3\n",
        "  GHOSTS_EDIBLE = 4\n",
        "  PILL = 5\n",
        "  NUM_ACTIONS = 5\n",
        "  MODES = ('regular', 'avoid', 'hunt', 'ambush', 'rush')\n",
        "\n",
        "  def __init__(self, mode, frame_cap=3000):\n",
        "    assert mode in PillEater.MODES\n",
        "    self.nghosts_init = 1\n",
        "    self.ghost_speed_init = 0.5\n",
        "    self.ghost_speed = self.ghost_speed_init\n",
        "    self.ghost_speed_increase = 0.1\n",
        "    self.end_on_collect = False\n",
        "    self.npills = 2\n",
        "    self.pill_duration = 20\n",
        "    self.seed = 123\n",
        "    self.discount = 1\n",
        "    self.stochasticity = 0.05\n",
        "    self.obs_is_rgb = True\n",
        "    self.frame_cap = frame_cap\n",
        "    self.safe_distance = 5\n",
        "    map_array = STANDARD_MAP\n",
        "    self.map, self.walls = parse_map(map_array)\n",
        "    self.map = np.array(self.map)\n",
        "    self.nactions = self.map.shape[2]\n",
        "    self.height = self.map.shape[0]\n",
        "    self.width = self.map.shape[1]\n",
        "    self.reverse_dir = (4, 5, 2, 3)\n",
        "    self.dir_vec = np.array([[0, 1], [-1, 0], [0, -1], [1, 0]])\n",
        "    self.world_state = dict(\n",
        "        pillman=self._make_pillman(),\n",
        "        ghosts=[],\n",
        "        food=np.zeros(shape=(self.height, self.width), dtype=np.float32),\n",
        "        pills=[None] * self.npills,\n",
        "        power=0\n",
        "    )\n",
        "    self.nplanes = 6\n",
        "    self.image = np.zeros(\n",
        "        shape=(self.height, self.width, self.nplanes), dtype=np.float32)\n",
        "    self.color_image = np.zeros(shape=(3, self.height, self.width),\n",
        "                                dtype=np.float32)\n",
        "    self.frame = 0\n",
        "    self.reward = 0.\n",
        "    self.pcontinue = 1.\n",
        "    self._init_level(1)\n",
        "    self._make_image()\n",
        "    self.mode = mode\n",
        "    self.timer = 0\n",
        "    if self.mode == 'regular':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = 1\n",
        "      self.big_pill_reward = 2\n",
        "      self.ghost_hunt_reward = 5\n",
        "      self.ghost_death_reward = 0\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = True\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'avoid':\n",
        "      self.step_reward = 0.1\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = -5\n",
        "      self.ghost_hunt_reward = -10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = True\n",
        "      self.timer_terminate = 128\n",
        "    elif self.mode == 'hunt':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = 0\n",
        "      self.big_pill_reward = 1\n",
        "      self.ghost_hunt_reward = 10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = True\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'ambush':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = 0\n",
        "      self.ghost_hunt_reward = 10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = True\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'rush':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = 10\n",
        "      self.ghost_hunt_reward = 0\n",
        "      self.ghost_death_reward = 0\n",
        "      self.all_pill_terminate = True\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "\n",
        "  def _make_pillman(self):\n",
        "    return self._make_actor(0)\n",
        "\n",
        "  def _make_enemy(self):\n",
        "    return self._make_actor(self.safe_distance)\n",
        "\n",
        "  def _make_actor(self, safe_distance):\n",
        "    \"\"\"Creates an actor.\n",
        "\n",
        "    An actor is a `ConfigDict` with a positions `pos` and a direction `dir`.\n",
        "    The position is an array with two elements, the height and width. The\n",
        "    direction is an integer representing the direction faced by the actor.\n",
        "\n",
        "    Args:\n",
        "      safe_distance: a `float`. The minimum distance from Pillman.\n",
        "\n",
        "    Returns:\n",
        "      A `ConfigDict`.\n",
        "    \"\"\"\n",
        "    actor = {}\n",
        "    if safe_distance > 0:\n",
        "      occupied_map = np.copy(self.walls)\n",
        "\n",
        "      from_ = (self.world_state['pillman']['pos'] - np.array(\n",
        "          [self.safe_distance, self.safe_distance]))\n",
        "      to = (self.world_state['pillman']['pos'] + np.array(\n",
        "          [self.safe_distance, self.safe_distance]))\n",
        "      from_[0] = max(from_[0], 1)\n",
        "      from_[1] = max(from_[1], 1)\n",
        "      to[0] = min(to[0], occupied_map.shape[0])\n",
        "      to[1] = min(to[1], occupied_map.shape[1])\n",
        "\n",
        "      occupied_map[from_[0]:to[0], from_[1]:to[1]] = 1\n",
        "\n",
        "      actor['pos'] = get_random_position(occupied_map)\n",
        "      actor['dir'] = np.random.randint(4)\n",
        "    else:\n",
        "      actor['pos'] = get_random_position(self.walls)\n",
        "      actor['dir'] = np.random.randint(4)\n",
        "\n",
        "    return actor\n",
        "\n",
        "  def _make_pill(self):\n",
        "    pill = dict(\n",
        "        pos=get_random_position(self.walls)\n",
        "    )\n",
        "    return pill\n",
        "\n",
        "  def _init_level(self, level):\n",
        "    \"\"\"Initialises the level.\"\"\"\n",
        "    self.level = level\n",
        "    self._fill_food(self.walls, self.world_state['food'])\n",
        "    self.world_state['pills'] = [self._make_pill() for _ in range(self.npills)]\n",
        "    self.world_state['pillman']['pos'] = get_random_position(self.walls)\n",
        "\n",
        "    self.nghosts = int(self.nghosts_init + math.floor((level - 1) / 2))\n",
        "    self.world_state['ghosts'] = [self._make_enemy() for _ in range(self.nghosts)]\n",
        "    self.world_state['power'] = 0\n",
        "\n",
        "    self.ghost_speed = (\n",
        "        self.ghost_speed_init + self.ghost_speed_increase * (level - 1))\n",
        "    self.timer = 0\n",
        "\n",
        "  def _fill_food(self, walls, food):\n",
        "    food.fill(-1)\n",
        "    food *= walls\n",
        "    food += 1\n",
        "    self.nfood = food.sum()\n",
        "\n",
        "  def _get_food(self, posx, posy):\n",
        "    self.reward += self.food_reward\n",
        "    self.world_state['food'][posx][posy] = 0\n",
        "    self.nfood -= 1\n",
        "    if self.nfood == 0 and self.all_food_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _get_pill(self, pill_index):\n",
        "    self.world_state['pills'].pop(pill_index)\n",
        "    self.reward += self.big_pill_reward\n",
        "    self.world_state['power'] = self.pill_duration\n",
        "    if (not self.world_state['pills']) and self.all_pill_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _kill_ghost(self, ghost_index):\n",
        "    self.world_state['ghosts'].pop(ghost_index)\n",
        "    self.reward += self.ghost_hunt_reward\n",
        "    if (not self.world_state['ghosts']) and self.all_ghosts_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _die_by_ghost(self):\n",
        "    self.reward += self.ghost_death_reward\n",
        "    self.pcontinue = 0\n",
        "\n",
        "  def _move_pillman(self, action):\n",
        "    \"\"\"Moves Pillman following the action in the proto `action_proto`.\"\"\"\n",
        "    action += 1  # our code is 1 based\n",
        "    pos = self.world_state['pillman']['pos']\n",
        "    pillman = self.world_state['pillman']\n",
        "    update_2d_pos(self.map, pos, action, pos)\n",
        "    if self.world_state['food'][pos[0]][pos[1]] == 1:\n",
        "      self._get_food(pos[0], pos[1])\n",
        "    for i, pill in enumerate(self.world_state['pills']):\n",
        "      pos = pill['pos']\n",
        "      if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "        self._get_pill(i)\n",
        "        break\n",
        "\n",
        "  def _move_ghost(self, ghost):\n",
        "    \"\"\"Moves the given ghost.\"\"\"\n",
        "    pos = ghost['pos']\n",
        "    new_pos = np.zeros(shape=(2,), dtype=np.float32)\n",
        "    pillman = self.world_state['pillman']\n",
        "    available = []\n",
        "    for i in range(2, self.nactions + 1):\n",
        "      update_2d_pos(self.map, pos, i, new_pos)\n",
        "      if pos[0] != new_pos[0] or pos[1] != new_pos[1]:\n",
        "        available.append(i)\n",
        "    n_available = len(available)\n",
        "    if n_available == 1:\n",
        "      ghost['dir'] = available[0]\n",
        "    elif n_available == 2:\n",
        "      if ghost['dir'] not in available:\n",
        "        if self.reverse_dir[ghost['dir'] - 2] == available[0]:\n",
        "          ghost['dir'] = available[1]\n",
        "        else:\n",
        "          ghost['dir'] = available[0]\n",
        "    else:\n",
        "      rev_dir = self.reverse_dir[ghost['dir'] - 2]\n",
        "      for i in range(n_available):\n",
        "        if available[i] == rev_dir:\n",
        "          available.pop(i)\n",
        "          n_available -= 1\n",
        "          break\n",
        "      prods = np.zeros(n_available, dtype=np.float32)\n",
        "      x = np.array(\n",
        "          [pillman['pos'][0] - pos[0], pillman['pos'][1] - pos[1]], dtype=np.float32)\n",
        "      norm = np.linalg.norm(x)\n",
        "      if norm > 0:\n",
        "        x *= 1. / norm\n",
        "        for i in range(n_available):\n",
        "          prods[i] = np.dot(x, self.dir_vec[available[i] - 2])\n",
        "        if self.world_state['power'] == 0:\n",
        "          if self.stochasticity > np.random.uniform():\n",
        "            j = np.random.randint(n_available)\n",
        "          else:\n",
        "            # move towards pillman:\n",
        "            j = np.argmax(prods)\n",
        "        else:\n",
        "          # run away from pillman:\n",
        "          j = np.argmin(prods)\n",
        "        ghost['dir'] = available[j]\n",
        "    update_2d_pos(self.map, pos, ghost['dir'], pos)\n",
        "\n",
        "  def _make_image(self):\n",
        "    \"\"\"Represents world in a `height x width x 6` `Tensor`.\"\"\"\n",
        "    self.image.fill(0)\n",
        "    self.image[:, :, PillEater.WALLS] = self.walls\n",
        "    self.image[:, :, PillEater.FOOD] = self.world_state['food']\n",
        "    self.image[self.world_state['pillman']['pos'][0], self.world_state['pillman']['pos'][1],\n",
        "               PillEater.PILLMAN] = 1\n",
        "    for ghost in self.world_state['ghosts']:\n",
        "      edibility = self.world_state['power'] / float(self.pill_duration)\n",
        "      self.image[ghost['pos'][0], ghost['pos'][1], PillEater.GHOSTS] = 1. - edibility\n",
        "      self.image[ghost['pos'][0], ghost['pos'][1], PillEater.GHOSTS_EDIBLE] = edibility\n",
        "    for pill in self.world_state['pills']:\n",
        "      self.image[pill['pos'][0], pill['pos'][1], PillEater.PILL] = 1\n",
        "    return self.image\n",
        "\n",
        "  def start(self):\n",
        "    \"\"\"Starts a new episode.\"\"\"\n",
        "    self.frame = 0\n",
        "    self._init_level(1)\n",
        "    self.reward = 0\n",
        "    self.pcontinue = 1\n",
        "    self.ghost_speed = self.ghost_speed_init\n",
        "    return self._make_image(), self.reward, self.pcontinue\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Advances environment one time-step following the given action.\"\"\"\n",
        "    self.frame += 1\n",
        "    pillman = self.world_state['pillman']\n",
        "    self.pcontinue = self.discount\n",
        "    self.reward = self.step_reward\n",
        "    self.timer += 1\n",
        "    # Update world state\n",
        "    self.world_state['power'] = max(0, self.world_state['power']-1)\n",
        "\n",
        "    # move pillman\n",
        "    self._move_pillman(action)\n",
        "\n",
        "    for i, ghost in enumerate(self.world_state['ghosts']):\n",
        "      # first check if pillman went onto a ghost\n",
        "      pos = ghost['pos']\n",
        "      if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "        if self.world_state['power'] == 0:\n",
        "          self._die_by_ghost()\n",
        "        else:\n",
        "          self._kill_ghost(i)\n",
        "          break\n",
        "      # Then move ghosts\n",
        "      speed = self.ghost_speed\n",
        "      if self.world_state['power'] != 0:\n",
        "        speed *= 0.5\n",
        "      if np.random.uniform() < speed:\n",
        "        self._move_ghost(ghost)\n",
        "        pos = ghost['pos']\n",
        "        # check if ghost went onto pillman\n",
        "        if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "          if self.world_state['power'] == 0:\n",
        "            self._die_by_ghost()\n",
        "          else:\n",
        "            self._kill_ghost(i)\n",
        "            # assume you can only eat one ghost per turn:\n",
        "            break\n",
        "    self._make_image()\n",
        "\n",
        "    # Check if level over\n",
        "    if self.timer == self.timer_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "    # Check if framecap reached\n",
        "    if self.frame_cap > 0 and self.frame >= self.frame_cap:\n",
        "      self.pcontinue = 0\n",
        "\n",
        "  def observation(self, agent_id=0):\n",
        "    return (self.reward,\n",
        "            self.pcontinue,\n",
        "            observation_as_rgb(self.image))"
      ],
      "metadata": {
        "id": "lV7LwX6UAKSE"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is from openai baseline\n",
        "#https://github.com/openai/baselines/tree/master/baselines/common/vec_env\n",
        "\n",
        "import numpy as np\n",
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def worker(remote, parent_remote, env_fn_wrapper):\n",
        "    parent_remote.close()\n",
        "    env = env_fn_wrapper.x()\n",
        "    while True:\n",
        "        cmd, data = remote.recv()\n",
        "        if cmd == 'step':\n",
        "            ob, reward, done, info = env.step(data)\n",
        "            if done:\n",
        "                ob = env.reset()\n",
        "            remote.send((ob, reward, done, info))\n",
        "        elif cmd == 'reset':\n",
        "            ob = env.reset()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'reset_task':\n",
        "            ob = env.reset_task()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'close':\n",
        "            remote.close()\n",
        "            break\n",
        "        elif cmd == 'get_spaces':\n",
        "            remote.send((env.observation_space, env.action_space))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class VecEnv(object):\n",
        "    \"\"\"\n",
        "    An abstract asynchronous, vectorized environment.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_envs, observation_space, action_space):\n",
        "        self.num_envs = num_envs\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset all the environments and return an array of\n",
        "        observations, or a tuple of observation arrays.\n",
        "        If step_async is still doing work, that work will\n",
        "        be cancelled and step_wait() should not be called\n",
        "        until step_async() is invoked again.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        \"\"\"\n",
        "        Tell all the environments to start taking a step\n",
        "        with the given actions.\n",
        "        Call step_wait() to get the results of the step.\n",
        "        You should not call this if a step_async run is\n",
        "        already pending.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_wait(self):\n",
        "        \"\"\"\n",
        "        Wait for the step taken with step_async().\n",
        "        Returns (obs, rews, dones, infos):\n",
        "         - obs: an array of observations, or a tuple of\n",
        "                arrays of observations.\n",
        "         - rews: an array of rewards\n",
        "         - dones: an array of \"episode done\" booleans\n",
        "         - infos: a sequence of info objects\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Clean up the environments' resources.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.step_async(actions)\n",
        "        return self.step_wait()\n",
        "\n",
        "\n",
        "class CloudpickleWrapper(object):\n",
        "    \"\"\"\n",
        "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
        "    \"\"\"\n",
        "    def __init__(self, x):\n",
        "        self.x = x\n",
        "    def __getstate__(self):\n",
        "        import cloudpickle\n",
        "        return cloudpickle.dumps(self.x)\n",
        "    def __setstate__(self, ob):\n",
        "        import pickle\n",
        "        self.x = pickle.loads(ob)\n",
        "\n",
        "class SubprocVecEnv(VecEnv):\n",
        "    def __init__(self, env_fns, spaces=None):\n",
        "        \"\"\"\n",
        "        envs: list of gym environments to run in subprocesses\n",
        "        \"\"\"\n",
        "        self.waiting = False\n",
        "        self.closed = False\n",
        "        nenvs = len(env_fns)\n",
        "        self.nenvs = nenvs\n",
        "        self.remotes, self.work_remotes = zip(*[Pipe() for _ in range(nenvs)])\n",
        "        self.ps = [Process(target=worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))\n",
        "            for (work_remote, remote, env_fn) in zip(self.work_remotes, self.remotes, env_fns)]\n",
        "        for p in self.ps:\n",
        "            p.daemon = True # if the main process crashes, we should not cause things to hang\n",
        "            p.start()\n",
        "        for remote in self.work_remotes:\n",
        "            remote.close()\n",
        "\n",
        "        self.remotes[0].send(('get_spaces', None))\n",
        "        observation_space, action_space = self.remotes[0].recv()\n",
        "        VecEnv.__init__(self, len(env_fns), observation_space, action_space)\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        for remote, action in zip(self.remotes, actions):\n",
        "            remote.send(('step', action))\n",
        "        self.waiting = True\n",
        "\n",
        "    def step_wait(self):\n",
        "        results = [remote.recv() for remote in self.remotes]\n",
        "        self.waiting = False\n",
        "        obs, rews, dones, infos = zip(*results)\n",
        "        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n",
        "\n",
        "    def reset(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def reset_task(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset_task', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def close(self):\n",
        "        if self.closed:\n",
        "            return\n",
        "        if self.waiting:\n",
        "            for remote in self.remotes:\n",
        "                remote.recv()\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('close', None))\n",
        "        for p in self.ps:\n",
        "            p.join()\n",
        "            self.closed = True\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nenvs"
      ],
      "metadata": {
        "id": "aXk4MMKsAVu3"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pacman Environment\n",
        "This part of the code contains the code for custom PACMAN environment. We will be comparing the performance of Imagination Augmented Agents and Deep Q-Networks on this environment in the further sections."
      ],
      "metadata": {
        "id": "qNEC-QcsAv-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJDbqUkR_qzV",
        "outputId": "a322b86c-2109-4f5b-c37c-3713a86db52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "class MiniPacman:\n",
        "    def __init__(self, mode, frame_cap):\n",
        "        self.mode      = mode\n",
        "        self.frame_cap = frame_cap\n",
        "\n",
        "        self.env = PillEater(mode=mode, frame_cap=frame_cap)\n",
        "\n",
        "        self.action_space      = spaces.Discrete(5)\n",
        "        self.observation_space = spaces.Box(low=0, high=1.0, shape=(3, 15, 19))\n",
        "\n",
        "    def step(self, action):\n",
        "        self.env.step(action)\n",
        "        env_reward, env_pcontinue, env_frame = self.env.observation()\n",
        "        self.done = env_pcontinue != 1\n",
        "        env_frame = env_frame.transpose(2, 0, 1)\n",
        "        return env_frame, env_reward, self.done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        image, _, _ = self.env.start()\n",
        "        image = observation_as_rgb(image)\n",
        "        self.done = False\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        return image"
      ],
      "metadata": {
        "id": "DecMGslS_xnM"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "tqR4K6Gf_6mQ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def displayImage(image, step, reward):\n",
        "    s = \"step\" + str(step) + \" reward \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uj9os6ZK_-pw"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = {\n",
        "    'w': 2,\n",
        "    'd': 1,\n",
        "    'a': 3,\n",
        "    's': 4,\n",
        "    ' ': 0\n",
        "}"
      ],
      "metadata": {
        "id": "VZiSD9ziAA8F"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODES = ('regular', 'avoid', 'hunt', 'ambush', 'rush')\n",
        "# frame_cap = 1000\n",
        "\n",
        "# mode = 'rush'\n",
        "\n",
        "# env = MiniPacman(mode, 1000)\n",
        "\n",
        "# state = env.reset()\n",
        "# done = False\n",
        "\n",
        "# total_reward = 0\n",
        "# step = 1\n",
        "\n",
        "# displayImage(state.transpose(1, 2, 0), step, total_reward)\n",
        "\n",
        "# while not done:\n",
        "#     x = input()\n",
        "#     clear_output()\n",
        "#     try:\n",
        "#         keys[x]\n",
        "#     except:\n",
        "#         print (\"Only 'w' 'a' 'd' 's'\")\n",
        "#         continue\n",
        "#     action = keys[x]\n",
        "\n",
        "#     next_state, reward, done, _ = env.step(action)\n",
        "#     total_reward += reward\n",
        "#     displayImage(next_state.transpose(1, 2, 0), step, total_reward)\n",
        "#     step += 1\n"
      ],
      "metadata": {
        "id": "Pck-B9gUA_Q7"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DQN\n",
        "This part contains the code for Deep Q-Network Agent which interacts with the PACMAN Environment."
      ],
      "metadata": {
        "id": "32rnldcunGSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "0yKLAfBwnFwu"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = False"
      ],
      "metadata": {
        "id": "uEKTtPBvnVtq"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "class Agent():\n",
        "    def __init__(self, epsilon_decay, epsilon_min,\n",
        "                       gamma, learning_rate, state_size, action_size,\n",
        "                       batch_size, training_threshold):\n",
        "        '''CREATING AND DEFINING BASIC PARAMETERS FOR TRAINING'''\n",
        "        self.movement_penalty = -1\n",
        "        # Change epsilon if model is already trained.\n",
        "        self.epsilon = 0.99\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.gamma = gamma\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.training_threshold = training_threshold\n",
        "\n",
        "        # Main Model\n",
        "        self.model = DQN(state_size, action_size)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Target Model\n",
        "        self.target_model = DQN(state_size, action_size)\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "        self.target_model.eval()\n",
        "\n",
        "        self.target_update_counter = 0\n",
        "\n",
        "        # Replay Memory\n",
        "        self.replay_memory = deque(maxlen=2000)\n",
        "\n",
        "    def update_replay_memory(self, state, action, reward, next_state, done):\n",
        "        '''UPDATING REPLAY MEMORY and DECAYING EPSILON'''\n",
        "        self.replay_memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def select_action(self, state):\n",
        "        '''DEFINING EPSILON GREEDY STRATEGY'''\n",
        "        if np.random.rand() > self.epsilon:\n",
        "            with torch.no_grad():\n",
        "                q_values = self.model(torch.tensor(state, dtype=torch.float32))\n",
        "                return np.argmax(q_values.numpy())\n",
        "        else:\n",
        "            return np.random.randint(0, self.action_size)\n",
        "\n",
        "    def train_agent(self):\n",
        "        '''TRAINING AGENT'''\n",
        "        if len(self.replay_memory) < self.training_threshold:\n",
        "            return\n",
        "\n",
        "        batch_size = min(self.batch_size, len(self.replay_memory))\n",
        "        minibatch = random.sample(self.replay_memory, batch_size)\n",
        "\n",
        "        observations = np.zeros((batch_size, self.state_size))\n",
        "        next_observations = np.zeros((batch_size, self.state_size))\n",
        "\n",
        "        action = []\n",
        "        reward = []\n",
        "        done = []\n",
        "\n",
        "        for sample_index in range(self.batch_size):\n",
        "            observations[sample_index] = minibatch[sample_index][0]\n",
        "            action.append(minibatch[sample_index][1])\n",
        "            reward.append(minibatch[sample_index][2])\n",
        "            next_observations[sample_index] = minibatch[sample_index][3]\n",
        "            done.append(minibatch[sample_index][4])\n",
        "\n",
        "        current_q_values = self.model(torch.tensor(observations, dtype=torch.float32))\n",
        "        future_q_values = self.target_model(torch.tensor(next_observations, dtype=torch.float32))\n",
        "\n",
        "        for index in range(self.batch_size):\n",
        "            if not done[index]:\n",
        "                current_q_values[index][action[index]] = reward[index] + self.gamma * torch.max(future_q_values[index]).item()\n",
        "            else:\n",
        "                current_q_values[index][action[index]] = reward[index]\n",
        "\n",
        "        loss = F.mse_loss(current_q_values, future_q_values.detach())\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        if done:\n",
        "            self.target_update_counter += 1\n",
        "\n",
        "        if self.target_update_counter > update_target_every:\n",
        "            self.target_model.load_state_dict(self.model.state_dict())\n",
        "            self.target_update_counter = 0"
      ],
      "metadata": {
        "id": "MNb0z-rhncju"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Agent\n",
        "This part of the code contains the training loop for the DQN agent. The plot of rewards v/s episodes does not show an increasing trend as we had to train the model for a very limited number of episodes due to resource constraints."
      ],
      "metadata": {
        "id": "YTkvTICMhZuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes= 5000\n",
        "epsilon_decay = 0.999995\n",
        "epsilon_min = 0.1\n",
        "gamma = 0.99\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "training_threshold = 1000\n",
        "update_target_every = 10\n",
        "load_model = False"
      ],
      "metadata": {
        "id": "TyqUx2Y-n03I"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the environment\n",
        "env = MiniPacman(mode='regular', frame_cap=1000)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = Agent(epsilon_decay=epsilon_decay, epsilon_min=epsilon_min,\n",
        "              gamma=gamma, learning_rate=learning_rate,\n",
        "              state_size=np.prod(env.observation_space.shape),\n",
        "              action_size=env.action_space.n,\n",
        "              batch_size=batch_size, training_threshold=training_threshold)\n",
        "\n",
        "# Lists to store episode rewards and losses\n",
        "episode_rewards = []\n",
        "\n",
        "for episode in range(1, num_episodes + 1):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, agent.state_size])\n",
        "    total_reward = 0\n",
        "\n",
        "    while True:\n",
        "        action = agent.select_action(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        next_state = np.reshape(next_state, [1, agent.state_size])\n",
        "        total_reward += reward\n",
        "\n",
        "        agent.update_replay_memory(state, action, reward, next_state, done)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    episode_rewards.append(total_reward)\n",
        "\n",
        "    # Train the agent\n",
        "    agent.train_agent()\n",
        "\n",
        "    # Print episode information\n",
        "    if episode % 100 == 0:\n",
        "        print(f\"Episode: {episode}/{num_episodes}, Total Reward: {total_reward}, Epsilon: {agent.epsilon}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m_8rFhExh1X",
        "outputId": "43f3194d-89be-454a-d34e-c331f7560254"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 100/5000, Total Reward: 22, Epsilon: 0.9535909915187536\n",
            "Episode: 200/5000, Total Reward: 8, Epsilon: 0.9305630083891768\n",
            "Episode: 300/5000, Total Reward: 6, Epsilon: 0.9073513265183664\n",
            "Episode: 400/5000, Total Reward: 5, Epsilon: 0.8818920480716756\n",
            "Episode: 500/5000, Total Reward: 11, Epsilon: 0.8628230240165585\n",
            "Episode: 600/5000, Total Reward: 6, Epsilon: 0.8381939578551394\n",
            "Episode: 700/5000, Total Reward: 17, Epsilon: 0.8096276416467862\n",
            "Episode: 800/5000, Total Reward: 15, Epsilon: 0.7830913508889686\n",
            "Episode: 900/5000, Total Reward: 7, Epsilon: 0.7675658754051533\n",
            "Episode: 1000/5000, Total Reward: 10, Epsilon: 0.7444154134035947\n",
            "Episode: 1100/5000, Total Reward: 17, Epsilon: 0.7251033269632623\n",
            "Episode: 1200/5000, Total Reward: 4, Epsilon: 0.7042856958631094\n",
            "Episode: 1300/5000, Total Reward: 10, Epsilon: 0.6881618338716268\n",
            "Episode: 1400/5000, Total Reward: 9, Epsilon: 0.6728678681376068\n",
            "Episode: 1500/5000, Total Reward: 20, Epsilon: 0.6493772903781514\n",
            "Episode: 1600/5000, Total Reward: 14, Epsilon: 0.6345200149075775\n",
            "Episode: 1700/5000, Total Reward: 10, Epsilon: 0.615831727329744\n",
            "Episode: 1800/5000, Total Reward: 3, Epsilon: 0.5950668014249201\n",
            "Episode: 1900/5000, Total Reward: 15, Epsilon: 0.5768882611968493\n",
            "Episode: 2000/5000, Total Reward: 7, Epsilon: 0.5582481132018393\n",
            "Episode: 2100/5000, Total Reward: 21, Epsilon: 0.5429669440069208\n",
            "Episode: 2200/5000, Total Reward: 24, Epsilon: 0.5305893573999726\n",
            "Episode: 2300/5000, Total Reward: 9, Epsilon: 0.5159466217289737\n",
            "Episode: 2400/5000, Total Reward: 6, Epsilon: 0.5045077784535537\n",
            "Episode: 2500/5000, Total Reward: 6, Epsilon: 0.49206370773742436\n",
            "Episode: 2600/5000, Total Reward: 12, Epsilon: 0.47923598090469055\n",
            "Episode: 2700/5000, Total Reward: 8, Epsilon: 0.4661945612333291\n",
            "Episode: 2800/5000, Total Reward: 12, Epsilon: 0.45475008223305496\n",
            "Episode: 2900/5000, Total Reward: 25, Epsilon: 0.4438194951889319\n",
            "Episode: 3000/5000, Total Reward: 15, Epsilon: 0.43447694582914126\n",
            "Episode: 3100/5000, Total Reward: 18, Epsilon: 0.42398701218176355\n",
            "Episode: 3200/5000, Total Reward: 8, Epsilon: 0.41295257554988374\n",
            "Episode: 3300/5000, Total Reward: 6, Epsilon: 0.40142980508779597\n",
            "Episode: 3400/5000, Total Reward: 24, Epsilon: 0.39186509147386694\n",
            "Episode: 3500/5000, Total Reward: 11, Epsilon: 0.3805537972280938\n",
            "Episode: 3600/5000, Total Reward: 5, Epsilon: 0.3692402357060938\n",
            "Episode: 3700/5000, Total Reward: 18, Epsilon: 0.3572630678111262\n",
            "Episode: 3800/5000, Total Reward: 4, Epsilon: 0.34812350987815976\n",
            "Episode: 3900/5000, Total Reward: 11, Epsilon: 0.3400277634305869\n",
            "Episode: 4000/5000, Total Reward: 2, Epsilon: 0.33089536360554184\n",
            "Episode: 4100/5000, Total Reward: 16, Epsilon: 0.3200243606249801\n",
            "Episode: 4200/5000, Total Reward: 14, Epsilon: 0.3112206201127071\n",
            "Episode: 4300/5000, Total Reward: 12, Epsilon: 0.30211779043932757\n",
            "Episode: 4400/5000, Total Reward: 7, Epsilon: 0.29506241694482005\n",
            "Episode: 4500/5000, Total Reward: 4, Epsilon: 0.2876434962641484\n",
            "Episode: 4600/5000, Total Reward: 16, Epsilon: 0.2811847133848076\n",
            "Episode: 4700/5000, Total Reward: 4, Epsilon: 0.27241502133918066\n",
            "Episode: 4800/5000, Total Reward: 1, Epsilon: 0.26554030930217964\n",
            "Episode: 4900/5000, Total Reward: 4, Epsilon: 0.2597167457790266\n",
            "Episode: 5000/5000, Total Reward: 5, Epsilon: 0.2521732935892146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0,num_episodes,1), episode_rewards)\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Rewards')"
      ],
      "metadata": {
        "id": "sBAR-WpMORYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "c33aa975-9a3b-45c3-adcd-0989eaba32bc"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Rewards')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "torch.save(agent.model.state_dict(), 'agent_weights.pth')"
      ],
      "metadata": {
        "id": "a8HQKz_kNPKe"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}