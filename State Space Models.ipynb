{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "Group members- Danish Vasdev (210298) Jatin Bansal (210465)\n",
        "\n",
        "In this project we have tried to find new types of environment models that can be used more effeciently with the I2A architecture\n",
        "\n",
        "The basic code of I2A is from its official implementation https://github.com/higgsfield/Imagination-Augmented-Agents/tree/master?tab=readme-ov-file\n",
        "\n",
        "Any other references used have been mentioned at the appropriate place."
      ],
      "metadata": {
        "id": "SIlQaauBkyLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup helpers"
      ],
      "metadata": {
        "id": "t7k2rUN5eFJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is written by @sracaniere from DeepMind\n",
        "#https://github.com/sracaniere\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "STANDARD_MAP = np.array([\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "\n",
        "\n",
        "def get_random_position(map_array):\n",
        "  \"\"\"Gets a random available position in a binary map array.\n",
        "\n",
        "  Args:\n",
        "    map_array: numpy array of the map to search an available position on.\n",
        "\n",
        "  Returns:\n",
        "    The chosen random position.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if there is no available space in the map.\n",
        "  \"\"\"\n",
        "  if map_array.sum() <= 0:\n",
        "    raise ValueError(\"There is no available space in the map.\")\n",
        "  map_dims = len(map_array.shape)\n",
        "  pos = np.zeros(map_dims, dtype=np.int32)\n",
        "  while True:\n",
        "    result = map_array\n",
        "    for i in range(map_dims):\n",
        "      pos[i] = np.random.randint(map_array.shape[i])\n",
        "      result = result[pos[i]]\n",
        "    if result == 0:\n",
        "      break\n",
        "  return pos\n",
        "\n",
        "\n",
        "def update_2d_pos(array_map, pos, action, pos_result):\n",
        "  posv = array_map[pos[0]][pos[1]][action - 1]\n",
        "  pos_result[0] = posv[0]\n",
        "  pos_result[1] = posv[1]\n",
        "  return pos_result\n",
        "\n",
        "\n",
        "def parse_map(map_array):\n",
        "  \"\"\"Parses a map when there are actions: stay, right, up, left, down.\n",
        "\n",
        "  Args:\n",
        "    map_array: 2D numpy array that contains the map.\n",
        "\n",
        "  Returns:\n",
        "    A 3D numpy array (height, width, actions) that contains the resulting state\n",
        "    for a given position + action, and a 2D numpy array (height, width) with the\n",
        "    walls of the map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if the map does not contain only zeros and ones.\n",
        "  \"\"\"\n",
        "  act_def = [[0, 0], [0, 1], [-1, 0], [0, -1], [1, 0]]\n",
        "  walls = np.zeros_like(map_array)\n",
        "  new_map_array = []\n",
        "  for i in range(map_array.shape[0]):\n",
        "    new_map_array.append([])\n",
        "    for j in range(map_array.shape[1]):\n",
        "      new_map_array[i].append([])\n",
        "      if map_array[i, j] == 0:\n",
        "        for k in range(len(act_def)):\n",
        "          new_map_array[i][j].append([i + act_def[k][0], j + act_def[k][1]])\n",
        "      elif map_array[i, j] == 1:\n",
        "        for k in range(len(act_def)):\n",
        "          new_map_array[i][j].append([i, j])\n",
        "        walls[i, j] = 1\n",
        "      else:\n",
        "        raise ValueError(\"Option not understood, %d\" % map_array[i, j])\n",
        "      for k in range(len(new_map_array[i][j])):\n",
        "        if map_array[new_map_array[i][j][k][0]][new_map_array[i][j][k][1]] == 1:\n",
        "          new_map_array[i][j][k][0] = i\n",
        "          new_map_array[i][j][k][1] = j\n",
        "  return np.array(new_map_array), walls\n",
        "\n",
        "\n",
        "def observation_as_rgb(obs):\n",
        "  \"\"\"Reduces the 6 channels of `obs` to 3 RGB.\n",
        "\n",
        "  Args:\n",
        "    obs: the observation as a numpy array.\n",
        "\n",
        "  Returns:\n",
        "    An RGB image in the form of a numpy array, with values between 0 and 1.\n",
        "  \"\"\"\n",
        "  height = obs.shape[0]\n",
        "  width = obs.shape[1]\n",
        "  rgb = np.zeros((height, width, 3), dtype=np.float32)\n",
        "  for x in range(height):\n",
        "    for y in range(width):\n",
        "      if obs[x, y, PillEater.PILLMAN] == 1:\n",
        "        rgb[x, y] = [0, 1, 0]\n",
        "      elif obs[x, y, PillEater.GHOSTS] > 0. or obs[x, y, PillEater.GHOSTS_EDIBLE] > 0.:\n",
        "        g = obs[x, y, PillEater.GHOSTS]\n",
        "        ge = obs[x, y, PillEater.GHOSTS_EDIBLE]\n",
        "        rgb[x, y] = [g + ge, ge, 0]\n",
        "      elif obs[x, y, PillEater.PILL] == 1:\n",
        "        rgb[x, y] = [0, 1, 1]\n",
        "      elif obs[x, y, PillEater.FOOD] == 1:\n",
        "        rgb[x, y] = [0, 0, 1]\n",
        "      elif obs[x, y, PillEater.WALLS] == 1:\n",
        "        rgb[x, y] = [1, 1, 1]\n",
        "  return rgb\n",
        "\n",
        "\n",
        "class PillEater(object):\n",
        "\n",
        "  WALLS = 0\n",
        "  FOOD = 1\n",
        "  PILLMAN = 2\n",
        "  GHOSTS = 3\n",
        "  GHOSTS_EDIBLE = 4\n",
        "  PILL = 5\n",
        "  NUM_ACTIONS = 5\n",
        "  MODES = ('regular', 'avoid', 'hunt', 'ambush', 'rush')\n",
        "\n",
        "  def __init__(self, mode, frame_cap=3000):\n",
        "    assert mode in PillEater.MODES\n",
        "    self.nghosts_init = 1\n",
        "    self.ghost_speed_init = 0.5\n",
        "    self.ghost_speed = self.ghost_speed_init\n",
        "    self.ghost_speed_increase = 0.1\n",
        "    self.end_on_collect = False\n",
        "    self.npills = 2\n",
        "    self.pill_duration = 20\n",
        "    self.seed = 123\n",
        "    self.discount = 1\n",
        "    self.stochasticity = 0.05\n",
        "    self.obs_is_rgb = True\n",
        "    self.frame_cap = frame_cap\n",
        "    self.safe_distance = 5\n",
        "    map_array = STANDARD_MAP\n",
        "    self.map, self.walls = parse_map(map_array)\n",
        "    self.map = np.array(self.map)\n",
        "    self.nactions = self.map.shape[2]\n",
        "    self.height = self.map.shape[0]\n",
        "    self.width = self.map.shape[1]\n",
        "    self.reverse_dir = (4, 5, 2, 3)\n",
        "    self.dir_vec = np.array([[0, 1], [-1, 0], [0, -1], [1, 0]])\n",
        "    self.world_state = dict(\n",
        "        pillman=self._make_pillman(),\n",
        "        ghosts=[],\n",
        "        food=np.zeros(shape=(self.height, self.width), dtype=np.float32),\n",
        "        pills=[None] * self.npills,\n",
        "        power=0\n",
        "    )\n",
        "    self.nplanes = 6\n",
        "    self.image = np.zeros(\n",
        "        shape=(self.height, self.width, self.nplanes), dtype=np.float32)\n",
        "    self.color_image = np.zeros(shape=(3, self.height, self.width),\n",
        "                                dtype=np.float32)\n",
        "    self.frame = 0\n",
        "    self.reward = 0.\n",
        "    self.pcontinue = 1.\n",
        "    self._init_level(1)\n",
        "    self._make_image()\n",
        "    self.mode = mode\n",
        "    self.timer = 0\n",
        "    if self.mode == 'regular':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = 1\n",
        "      self.big_pill_reward = 2\n",
        "      self.ghost_hunt_reward = 5\n",
        "      self.ghost_death_reward = 0\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = True\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'avoid':\n",
        "      self.step_reward = 0.1\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = -5\n",
        "      self.ghost_hunt_reward = -10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = True\n",
        "      self.timer_terminate = 128\n",
        "    elif self.mode == 'hunt':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = 0\n",
        "      self.big_pill_reward = 1\n",
        "      self.ghost_hunt_reward = 10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = True\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'ambush':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = 0\n",
        "      self.ghost_hunt_reward = 10\n",
        "      self.ghost_death_reward = -20\n",
        "      self.all_pill_terminate = False\n",
        "      self.all_ghosts_terminate = True\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "    elif self.mode == 'rush':\n",
        "      self.step_reward = 0\n",
        "      self.food_reward = -0.1\n",
        "      self.big_pill_reward = 10\n",
        "      self.ghost_hunt_reward = 0\n",
        "      self.ghost_death_reward = 0\n",
        "      self.all_pill_terminate = True\n",
        "      self.all_ghosts_terminate = False\n",
        "      self.all_food_terminate = False\n",
        "      self.timer_terminate = -1\n",
        "\n",
        "  def _make_pillman(self):\n",
        "    return self._make_actor(0)\n",
        "\n",
        "  def _make_enemy(self):\n",
        "    return self._make_actor(self.safe_distance)\n",
        "\n",
        "  def _make_actor(self, safe_distance):\n",
        "    \"\"\"Creates an actor.\n",
        "\n",
        "    An actor is a `ConfigDict` with a positions `pos` and a direction `dir`.\n",
        "    The position is an array with two elements, the height and width. The\n",
        "    direction is an integer representing the direction faced by the actor.\n",
        "\n",
        "    Args:\n",
        "      safe_distance: a `float`. The minimum distance from Pillman.\n",
        "\n",
        "    Returns:\n",
        "      A `ConfigDict`.\n",
        "    \"\"\"\n",
        "    actor = {}\n",
        "    if safe_distance > 0:\n",
        "      occupied_map = np.copy(self.walls)\n",
        "\n",
        "      from_ = (self.world_state['pillman']['pos'] - np.array(\n",
        "          [self.safe_distance, self.safe_distance]))\n",
        "      to = (self.world_state['pillman']['pos'] + np.array(\n",
        "          [self.safe_distance, self.safe_distance]))\n",
        "      from_[0] = max(from_[0], 1)\n",
        "      from_[1] = max(from_[1], 1)\n",
        "      to[0] = min(to[0], occupied_map.shape[0])\n",
        "      to[1] = min(to[1], occupied_map.shape[1])\n",
        "\n",
        "      occupied_map[from_[0]:to[0], from_[1]:to[1]] = 1\n",
        "\n",
        "      actor['pos'] = get_random_position(occupied_map)\n",
        "      actor['dir'] = np.random.randint(4)\n",
        "    else:\n",
        "      actor['pos'] = get_random_position(self.walls)\n",
        "      actor['dir'] = np.random.randint(4)\n",
        "\n",
        "    return actor\n",
        "\n",
        "  def _make_pill(self):\n",
        "    pill = dict(\n",
        "        pos=get_random_position(self.walls)\n",
        "    )\n",
        "    return pill\n",
        "\n",
        "  def _init_level(self, level):\n",
        "    \"\"\"Initialises the level.\"\"\"\n",
        "    self.level = level\n",
        "    self._fill_food(self.walls, self.world_state['food'])\n",
        "    self.world_state['pills'] = [self._make_pill() for _ in range(self.npills)]\n",
        "    self.world_state['pillman']['pos'] = get_random_position(self.walls)\n",
        "\n",
        "    self.nghosts = int(self.nghosts_init + math.floor((level - 1) / 2))\n",
        "    self.world_state['ghosts'] = [self._make_enemy() for _ in range(self.nghosts)]\n",
        "    self.world_state['power'] = 0\n",
        "\n",
        "    self.ghost_speed = (\n",
        "        self.ghost_speed_init + self.ghost_speed_increase * (level - 1))\n",
        "    self.timer = 0\n",
        "\n",
        "  def _fill_food(self, walls, food):\n",
        "    food.fill(-1)\n",
        "    food *= walls\n",
        "    food += 1\n",
        "    self.nfood = food.sum()\n",
        "\n",
        "  def _get_food(self, posx, posy):\n",
        "    self.reward += self.food_reward\n",
        "    self.world_state['food'][posx][posy] = 0\n",
        "    self.nfood -= 1\n",
        "    if self.nfood == 0 and self.all_food_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _get_pill(self, pill_index):\n",
        "    self.world_state['pills'].pop(pill_index)\n",
        "    self.reward += self.big_pill_reward\n",
        "    self.world_state['power'] = self.pill_duration\n",
        "    if (not self.world_state['pills']) and self.all_pill_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _kill_ghost(self, ghost_index):\n",
        "    self.world_state['ghosts'].pop(ghost_index)\n",
        "    self.reward += self.ghost_hunt_reward\n",
        "    if (not self.world_state['ghosts']) and self.all_ghosts_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "  def _die_by_ghost(self):\n",
        "    self.reward += self.ghost_death_reward\n",
        "    self.pcontinue = 0\n",
        "\n",
        "  def _move_pillman(self, action):\n",
        "    \"\"\"Moves Pillman following the action in the proto `action_proto`.\"\"\"\n",
        "    action += 1  # our code is 1 based\n",
        "    pos = self.world_state['pillman']['pos']\n",
        "    pillman = self.world_state['pillman']\n",
        "    update_2d_pos(self.map, pos, action, pos)\n",
        "    if self.world_state['food'][pos[0]][pos[1]] == 1:\n",
        "      self._get_food(pos[0], pos[1])\n",
        "    for i, pill in enumerate(self.world_state['pills']):\n",
        "      pos = pill['pos']\n",
        "      if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "        self._get_pill(i)\n",
        "        break\n",
        "\n",
        "  def _move_ghost(self, ghost):\n",
        "    \"\"\"Moves the given ghost.\"\"\"\n",
        "    pos = ghost['pos']\n",
        "    new_pos = np.zeros(shape=(2,), dtype=np.float32)\n",
        "    pillman = self.world_state['pillman']\n",
        "    available = []\n",
        "    for i in range(2, self.nactions + 1):\n",
        "      update_2d_pos(self.map, pos, i, new_pos)\n",
        "      if pos[0] != new_pos[0] or pos[1] != new_pos[1]:\n",
        "        available.append(i)\n",
        "    n_available = len(available)\n",
        "    if n_available == 1:\n",
        "      ghost['dir'] = available[0]\n",
        "    elif n_available == 2:\n",
        "      if ghost['dir'] not in available:\n",
        "        if self.reverse_dir[ghost['dir'] - 2] == available[0]:\n",
        "          ghost['dir'] = available[1]\n",
        "        else:\n",
        "          ghost['dir'] = available[0]\n",
        "    else:\n",
        "      rev_dir = self.reverse_dir[ghost['dir'] - 2]\n",
        "      for i in range(n_available):\n",
        "        if available[i] == rev_dir:\n",
        "          available.pop(i)\n",
        "          n_available -= 1\n",
        "          break\n",
        "      prods = np.zeros(n_available, dtype=np.float32)\n",
        "      x = np.array(\n",
        "          [pillman['pos'][0] - pos[0], pillman['pos'][1] - pos[1]], dtype=np.float32)\n",
        "      norm = np.linalg.norm(x)\n",
        "      if norm > 0:\n",
        "        x *= 1. / norm\n",
        "        for i in range(n_available):\n",
        "          prods[i] = np.dot(x, self.dir_vec[available[i] - 2])\n",
        "        if self.world_state['power'] == 0:\n",
        "          if self.stochasticity > np.random.uniform():\n",
        "            j = np.random.randint(n_available)\n",
        "          else:\n",
        "            # move towards pillman:\n",
        "            j = np.argmax(prods)\n",
        "        else:\n",
        "          # run away from pillman:\n",
        "          j = np.argmin(prods)\n",
        "        ghost['dir'] = available[j]\n",
        "    update_2d_pos(self.map, pos, ghost['dir'], pos)\n",
        "\n",
        "  def _make_image(self):\n",
        "    \"\"\"Represents world in a `height x width x 6` `Tensor`.\"\"\"\n",
        "    self.image.fill(0)\n",
        "    self.image[:, :, PillEater.WALLS] = self.walls\n",
        "    self.image[:, :, PillEater.FOOD] = self.world_state['food']\n",
        "    self.image[self.world_state['pillman']['pos'][0], self.world_state['pillman']['pos'][1],\n",
        "               PillEater.PILLMAN] = 1\n",
        "    for ghost in self.world_state['ghosts']:\n",
        "      edibility = self.world_state['power'] / float(self.pill_duration)\n",
        "      self.image[ghost['pos'][0], ghost['pos'][1], PillEater.GHOSTS] = 1. - edibility\n",
        "      self.image[ghost['pos'][0], ghost['pos'][1], PillEater.GHOSTS_EDIBLE] = edibility\n",
        "    for pill in self.world_state['pills']:\n",
        "      self.image[pill['pos'][0], pill['pos'][1], PillEater.PILL] = 1\n",
        "    return self.image\n",
        "\n",
        "  def start(self):\n",
        "    \"\"\"Starts a new episode.\"\"\"\n",
        "    self.frame = 0\n",
        "    self._init_level(1)\n",
        "    self.reward = 0\n",
        "    self.pcontinue = 1\n",
        "    self.ghost_speed = self.ghost_speed_init\n",
        "    return self._make_image(), self.reward, self.pcontinue\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"Advances environment one time-step following the given action.\"\"\"\n",
        "    self.frame += 1\n",
        "    pillman = self.world_state['pillman']\n",
        "    self.pcontinue = self.discount\n",
        "    self.reward = self.step_reward\n",
        "    self.timer += 1\n",
        "    # Update world state\n",
        "    self.world_state['power'] = max(0, self.world_state['power']-1)\n",
        "\n",
        "    # move pillman\n",
        "    self._move_pillman(action)\n",
        "\n",
        "    for i, ghost in enumerate(self.world_state['ghosts']):\n",
        "      # first check if pillman went onto a ghost\n",
        "      pos = ghost['pos']\n",
        "      if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "        if self.world_state['power'] == 0:\n",
        "          self._die_by_ghost()\n",
        "        else:\n",
        "          self._kill_ghost(i)\n",
        "          break\n",
        "      # Then move ghosts\n",
        "      speed = self.ghost_speed\n",
        "      if self.world_state['power'] != 0:\n",
        "        speed *= 0.5\n",
        "      if np.random.uniform() < speed:\n",
        "        self._move_ghost(ghost)\n",
        "        pos = ghost['pos']\n",
        "        # check if ghost went onto pillman\n",
        "        if pos[0] == pillman['pos'][0] and pos[1] == pillman['pos'][1]:\n",
        "          if self.world_state['power'] == 0:\n",
        "            self._die_by_ghost()\n",
        "          else:\n",
        "            self._kill_ghost(i)\n",
        "            # assume you can only eat one ghost per turn:\n",
        "            break\n",
        "    self._make_image()\n",
        "\n",
        "    # Check if level over\n",
        "    if self.timer == self.timer_terminate:\n",
        "      self._init_level(self.level + 1)\n",
        "\n",
        "    # Check if framecap reached\n",
        "    if self.frame_cap > 0 and self.frame >= self.frame_cap:\n",
        "      self.pcontinue = 0\n",
        "\n",
        "  def observation(self, agent_id=0):\n",
        "    return (self.reward,\n",
        "            self.pcontinue,\n",
        "            observation_as_rgb(self.image))"
      ],
      "metadata": {
        "id": "fYHUPWB-eC7h"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is from openai baseline\n",
        "#https://github.com/openai/baselines/tree/master/baselines/common/vec_env\n",
        "\n",
        "import numpy as np\n",
        "from multiprocessing import Process, Pipe\n",
        "\n",
        "def worker(remote, parent_remote, env_fn_wrapper):\n",
        "    parent_remote.close()\n",
        "    env = env_fn_wrapper.x()\n",
        "    while True:\n",
        "        cmd, data = remote.recv()\n",
        "        if cmd == 'step':\n",
        "            ob, reward, done, info = env.step(data)\n",
        "            if done:\n",
        "                ob = env.reset()\n",
        "            remote.send((ob, reward, done, info))\n",
        "        elif cmd == 'reset':\n",
        "            ob = env.reset()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'reset_task':\n",
        "            ob = env.reset_task()\n",
        "            remote.send(ob)\n",
        "        elif cmd == 'close':\n",
        "            remote.close()\n",
        "            break\n",
        "        elif cmd == 'get_spaces':\n",
        "            remote.send((env.observation_space, env.action_space))\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "class VecEnv(object):\n",
        "    \"\"\"\n",
        "    An abstract asynchronous, vectorized environment.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_envs, observation_space, action_space):\n",
        "        self.num_envs = num_envs\n",
        "        self.observation_space = observation_space\n",
        "        self.action_space = action_space\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset all the environments and return an array of\n",
        "        observations, or a tuple of observation arrays.\n",
        "        If step_async is still doing work, that work will\n",
        "        be cancelled and step_wait() should not be called\n",
        "        until step_async() is invoked again.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        \"\"\"\n",
        "        Tell all the environments to start taking a step\n",
        "        with the given actions.\n",
        "        Call step_wait() to get the results of the step.\n",
        "        You should not call this if a step_async run is\n",
        "        already pending.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step_wait(self):\n",
        "        \"\"\"\n",
        "        Wait for the step taken with step_async().\n",
        "        Returns (obs, rews, dones, infos):\n",
        "         - obs: an array of observations, or a tuple of\n",
        "                arrays of observations.\n",
        "         - rews: an array of rewards\n",
        "         - dones: an array of \"episode done\" booleans\n",
        "         - infos: a sequence of info objects\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        Clean up the environments' resources.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step(self, actions):\n",
        "        self.step_async(actions)\n",
        "        return self.step_wait()\n",
        "\n",
        "\n",
        "class CloudpickleWrapper(object):\n",
        "    \"\"\"\n",
        "    Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n",
        "    \"\"\"\n",
        "    def __init__(self, x):\n",
        "        self.x = x\n",
        "    def __getstate__(self):\n",
        "        import cloudpickle\n",
        "        return cloudpickle.dumps(self.x)\n",
        "    def __setstate__(self, ob):\n",
        "        import pickle\n",
        "        self.x = pickle.loads(ob)\n",
        "\n",
        "class SubprocVecEnv(VecEnv):\n",
        "    def __init__(self, env_fns, spaces=None):\n",
        "        \"\"\"\n",
        "        envs: list of gym environments to run in subprocesses\n",
        "        \"\"\"\n",
        "        self.waiting = False\n",
        "        self.closed = False\n",
        "        nenvs = len(env_fns)\n",
        "        self.nenvs = nenvs\n",
        "        self.remotes, self.work_remotes = zip(*[Pipe() for _ in range(nenvs)])\n",
        "        self.ps = [Process(target=worker, args=(work_remote, remote, CloudpickleWrapper(env_fn)))\n",
        "            for (work_remote, remote, env_fn) in zip(self.work_remotes, self.remotes, env_fns)]\n",
        "        for p in self.ps:\n",
        "            p.daemon = True # if the main process crashes, we should not cause things to hang\n",
        "            p.start()\n",
        "        for remote in self.work_remotes:\n",
        "            remote.close()\n",
        "\n",
        "        self.remotes[0].send(('get_spaces', None))\n",
        "        observation_space, action_space = self.remotes[0].recv()\n",
        "        VecEnv.__init__(self, len(env_fns), observation_space, action_space)\n",
        "\n",
        "    def step_async(self, actions):\n",
        "        for remote, action in zip(self.remotes, actions):\n",
        "            remote.send(('step', action))\n",
        "        self.waiting = True\n",
        "\n",
        "    def step_wait(self):\n",
        "        results = [remote.recv() for remote in self.remotes]\n",
        "        self.waiting = False\n",
        "        obs, rews, dones, infos = zip(*results)\n",
        "        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n",
        "\n",
        "    def reset(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def reset_task(self):\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('reset_task', None))\n",
        "        return np.stack([remote.recv() for remote in self.remotes])\n",
        "\n",
        "    def close(self):\n",
        "        if self.closed:\n",
        "            return\n",
        "        if self.waiting:\n",
        "            for remote in self.remotes:\n",
        "                remote.recv()\n",
        "        for remote in self.remotes:\n",
        "            remote.send(('close', None))\n",
        "        for p in self.ps:\n",
        "            p.join()\n",
        "            self.closed = True\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.nenvs"
      ],
      "metadata": {
        "id": "xwxdXSmPlOu7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MiniPacman"
      ],
      "metadata": {
        "id": "aSPQO33odYtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLF-xPF1czOw",
        "outputId": "c895e281-f6ed-4c0e-f61e-60088f0b1640"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KioMlJRqbeZ-"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "\n",
        "class MiniPacman:\n",
        "    def __init__(self, mode, frame_cap):\n",
        "        self.mode      = mode\n",
        "        self.frame_cap = frame_cap\n",
        "\n",
        "        self.env = PillEater(mode=mode, frame_cap=frame_cap)\n",
        "\n",
        "        self.action_space      = spaces.Discrete(5)\n",
        "        self.observation_space = spaces.Box(low=0, high=1.0, shape=(3, 15, 19))\n",
        "\n",
        "    def step(self, action):\n",
        "        self.env.step(action)\n",
        "        env_reward, env_pcontinue, env_frame = self.env.observation()\n",
        "        self.done = env_pcontinue != 1\n",
        "        env_frame = env_frame.transpose(2, 0, 1)\n",
        "        return env_frame, env_reward, self.done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        image, _, _ = self.env.start()\n",
        "        image = observation_as_rgb(image)\n",
        "        self.done = False\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        return image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment model\n",
        "\n",
        "This is the environment model originally used in the research paper. It is an auto regressive model that uses RNNs to capture the time dependent behaviour of the environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "qvuAIcq7dOC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS45bv9cdgyC",
        "outputId": "7440bc69-a44c-4ec1-e137-8c538e317c11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_shape, n1, n2, n3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.in_shape = in_shape\n",
        "        self.n1 = n1\n",
        "        self.n2 = n2\n",
        "        self.n3 = n3\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=in_shape[1:])\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0] * 2, n1, kernel_size=1, stride=2, padding=6),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n1, n1, kernel_size=10, stride=1, padding=(5, 6)),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0] * 2, n2, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n2, n2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(n1 + n2,  n3, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.pool_and_inject(inputs)\n",
        "        x = torch.cat([self.conv1(x), self.conv2(x)], 1)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.cat([x, inputs], 1)\n",
        "        return x\n",
        "\n",
        "    def pool_and_inject(self, x):\n",
        "        pooled     = self.maxpool(x)\n",
        "        tiled      = pooled.expand((x.size(0),) + self.in_shape)\n",
        "        out        = torch.cat([tiled, x], 1)\n",
        "        return out\n",
        "\n",
        "\n",
        "class EnvModel(nn.Module):\n",
        "    def __init__(self, in_shape, num_pixels, num_rewards):\n",
        "        super(EnvModel, self).__init__()\n",
        "\n",
        "        width  = in_shape[1]\n",
        "        height = in_shape[2]\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(8, 64, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.basic_block1 = BasicBlock((64, width, height), 16, 32, 64)\n",
        "        self.basic_block2 = BasicBlock((128, width, height), 16, 32, 64)\n",
        "\n",
        "        self.image_conv = nn.Sequential(\n",
        "            nn.Conv2d(192, 256, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.image_fc = nn.Linear(256, num_pixels)\n",
        "\n",
        "        self.reward_conv = nn.Sequential(\n",
        "            nn.Conv2d(192, 64, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.reward_fc    = nn.Linear(64 * width * height, num_rewards)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "\n",
        "        x = self.conv(inputs)\n",
        "        x = self.basic_block1(x)\n",
        "        x = self.basic_block2(x)\n",
        "\n",
        "        image = self.image_conv(x)\n",
        "        image = image.permute(0, 2, 3, 1).contiguous().view(-1, 256)\n",
        "        image = self.image_fc(image)\n",
        "\n",
        "        reward = self.reward_conv(x)\n",
        "        reward = reward.view(batch_size, -1)\n",
        "        reward = self.reward_fc(reward)\n",
        "\n",
        "        return image, reward"
      ],
      "metadata": {
        "id": "pnlM3cmCc_GK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Actor Critic\n",
        "We use a simple model free actor critic model to make the model free path of the I2A agent, as well as to train the environment model against"
      ],
      "metadata": {
        "id": "c1DCGLhpekAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class OnPolicy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OnPolicy, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def act(self, x, deterministic=False):\n",
        "        logit, value = self.forward(x)\n",
        "        probs = F.softmax(logit)\n",
        "\n",
        "        if deterministic:\n",
        "            action = probs.max(1)[1]\n",
        "        else:\n",
        "            action = probs.multinomial()\n",
        "\n",
        "        return action\n",
        "\n",
        "    def evaluate_actions(self, x, action):\n",
        "        logit, value = self.forward(x)\n",
        "\n",
        "        probs     = F.softmax(logit)\n",
        "        log_probs = F.log_softmax(logit)\n",
        "\n",
        "        action_log_probs = log_probs.gather(1, action)\n",
        "        entropy = -(probs * log_probs).sum(1).mean()\n",
        "\n",
        "        return logit, action_log_probs, value, entropy\n",
        "\n",
        "\n",
        "class ActorCritic(OnPolicy):\n",
        "    def __init__(self, in_shape, num_actions):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.in_shape = in_shape\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0], 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size(), 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.critic  = nn.Linear(256, 1)\n",
        "        self.actor   = nn.Linear(256, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        logit = self.actor(x)\n",
        "        value = self.critic(x)\n",
        "        return logit, value\n",
        "\n",
        "    def feature_size(self):\n",
        "        return self.features(Variable(torch.zeros(1, *self.in_shape))).view(1, -1).size(1)\n",
        "\n",
        "\n",
        "class RolloutStorage(object):\n",
        "    def __init__(self, num_steps, num_envs, state_shape):\n",
        "        self.num_steps = num_steps\n",
        "        self.num_envs  = num_envs\n",
        "        self.states  = torch.zeros(num_steps + 1, num_envs, *state_shape)\n",
        "        self.rewards = torch.zeros(num_steps,     num_envs, 1)\n",
        "        self.masks   = torch.ones(num_steps  + 1, num_envs, 1)\n",
        "        self.actions = torch.zeros(num_steps,     num_envs, 1).long()\n",
        "        self.use_cuda = False\n",
        "\n",
        "    def cuda(self):\n",
        "        self.use_cuda  = True\n",
        "        self.states    = self.states.cuda()\n",
        "        self.rewards   = self.rewards.cuda()\n",
        "        self.masks     = self.masks.cuda()\n",
        "        self.actions   = self.actions.cuda()\n",
        "\n",
        "    def insert(self, step, state, action, reward, mask):\n",
        "        self.states[step + 1].copy_(state)\n",
        "        self.actions[step].copy_(action)\n",
        "        self.rewards[step].copy_(reward)\n",
        "        self.masks[step + 1].copy_(mask)\n",
        "\n",
        "    def after_update(self):\n",
        "        self.states[0].copy_(self.states[-1])\n",
        "        self.masks[0].copy_(self.masks[-1])\n",
        "\n",
        "    def compute_returns(self, next_value, gamma):\n",
        "        returns   = torch.zeros(self.num_steps + 1, self.num_envs, 1)\n",
        "        if self.use_cuda:\n",
        "            returns = returns.cuda()\n",
        "        returns[-1] = next_value\n",
        "        for step in reversed(range(self.num_steps)):\n",
        "            returns[step] = returns[step + 1] * gamma * self.masks[step + 1] + self.rewards[step]\n",
        "        return returns[:-1]"
      ],
      "metadata": {
        "id": "fyzUqSBYejnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02031664-14a2-4cef-b347-4fa2de13ffb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MiniPacman experiment"
      ],
      "metadata": {
        "id": "JJ0Vypdlevh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xvhyYJC9fFCh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def displayImage(image, step, reward):\n",
        "    s = \"step\" + str(step) + \" reward \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-shUbEQHfPyo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = {\n",
        "    'w': 2,\n",
        "    'd': 1,\n",
        "    'a': 3,\n",
        "    's': 4,\n",
        "    ' ': 0\n",
        "}"
      ],
      "metadata": {
        "id": "OX7g5CR3fTV_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODES = ('regular', 'avoid', 'hunt', 'ambush', 'rush')\n",
        "frame_cap = 1000\n",
        "\n",
        "mode = 'rush'\n",
        "\n",
        "env = MiniPacman(mode, 1000)\n",
        "\n",
        "state = env.reset()\n",
        "done = False\n",
        "\n",
        "total_reward = 0\n",
        "step = 1\n",
        "\n",
        "displayImage(state.transpose(1, 2, 0), step, total_reward)\n",
        "\n",
        "while not done:\n",
        "    x = input()\n",
        "    clear_output()\n",
        "    try:\n",
        "        keys[x]\n",
        "    except:\n",
        "        print(\"Only 'w' 'a' 'd' 's'\")\n",
        "        continue\n",
        "    action = keys[x]\n",
        "\n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    displayImage(next_state.transpose(1, 2, 0), step, total_reward)\n",
        "    step += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "4VrUFZVqfVmv",
        "outputId": "002c854b-ae92-4599-ef0e-71c1101bab3c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGzCAYAAACy+RS/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAp0UlEQVR4nO3de3xU9Z3/8fcQYIIhGQySQEqAwCIgYKrhsghUkZSQUgS3iFKWAna9YJCyWAR2FwJ1NUUtUhXBsgp0xQv6ANzVLRSQu1wNKF4KAVOMctWVmQQkQOb7+6M/ZhlzJ2cmyXxfz8djHg/mnO855/Odb86cN2fOzHEZY4wAAIC1GtR2AQAAoHYRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAFhh9uzZcrlctV0GUCcRBoAwefXVVzV//vywbKuoqEjZ2dkaPHiw4uPj5XK5tHTp0rBsOxJ89dVXGjlypJo1a6a4uDgNGzZMn3/+eW2XBYQMYQAIk3CGga+//lq/+c1v9Nlnnyk1NTUs24wURUVFGjBggDZv3qx/+Zd/0Zw5c7Rv3z7deuut+uabb2q7PCAkGtZ2AQCc16pVKx0/flwtW7bU3r171bNnzxqv8+zZs4qJiXGgutC4dOmS/H6/GjduXKP1vPDCC8rLy9Pu3bsDr1tmZqa6deum3/3ud3riiSecKBeoUzgzADigsLBQkydPVrt27eR2u5WQkKAf//jHys3NlSTddtttevfdd3X06FG5XC65XC61a9cusHxxcbGys7P1d3/3d3K73UpOTtajjz6q4uLioO24XC5NnDhRy5cvV6dOnRQdHa20tDRt2bIlqJ3b7VbLli2vuj/jxo1T06ZNdeTIEf3kJz9RbGysRo8eLUny+/2aP3++unbtqujoaCUmJuqBBx7Qt99+G1h+ypQpat68ua68KerDDz8sl8ulZ599NjDt5MmTcrlcWrhwoSTpwoULmjVrltLS0uTxeBQTE6P+/ftr48aNQfX99a9/lcvl0tNPP6358+erQ4cOcrvd+vTTTyVJ27ZtU8+ePRUdHa0OHTroxRdfrHLf33rrLfXs2TMoQHXu3FkDBw7UihUrqvEqAvUHZwYABzz44IN66623NHHiRN1www365ptvtG3bNn322We6+eab9a//+q/yer368ssv9cwzz0iSmjZtKulvB9c77rhD27Zt0/33368uXbrowIEDeuaZZ3To0CGtXr06aFubN2/WG2+8oUmTJsntduuFF17Q4MGDtXv3bnXr1s2xPl26dEkZGRnq16+fnn76aV1zzTWSpAceeEBLly7V+PHjNWnSJOXn5+v555/Xvn37tH37djVq1Ej9+/fXM888o08++SRQ09atW9WgQQNt3bpVkyZNCkyTpB/96EeSJJ/Pp//4j//QqFGjdN9996mwsFAvvfSSMjIytHv3bv3whz8MqnHJkiU6f/687r//frndbsXHx+vAgQMaNGiQWrRoodmzZ+vSpUvKzs5WYmJipX32+/366KOPdO+995aa16tXL/35z39WYWGhYmNjr/p1BeokA6DGPB6PycrKqrDNkCFDTNu2bUtN/8///E/ToEEDs3Xr1qDpixYtMpLM9u3bA9MkGUlm7969gWlHjx410dHR5s477yxzu3v27DGSzJIlS6rcn7FjxxpJZvr06UHTt27daiSZ5cuXB01fs2ZN0PRTp04ZSeaFF14wxhhz5swZ06BBA3PXXXeZxMTEwHKTJk0y8fHxxu/3G2OMuXTpkikuLg5a97fffmsSExPNvffeG5iWn59vJJm4uDhz6tSpoPbDhw830dHR5ujRo4Fpn376qYmKijKVveWdPn3aSDK/+c1vSs1bsGCBkWT+8pe/VLgOoD7iYwLAAc2aNdOuXbt07Nixai/75ptvqkuXLurcubO+/vrrwOP222+XpFKnyPv06aO0tLTA8zZt2mjYsGFau3atSkpKataR75kwYUKpWj0ej3784x8H1ZqWlqamTZsGam3RooU6d+4c+Phi+/btioqK0tSpU3Xy5Enl5eVJ+tuZgX79+gW+8hcVFRX4zN/v9+t///d/denSJfXo0SPwkcuVfvazn6lFixaB5yUlJVq7dq2GDx+uNm3aBKZ36dJFGRkZlfb3u+++k/S3j1m+Lzo6OqgNEEkIA4ADnnzySX388cdKTk5Wr169NHv27Cp/FS0vL0+ffPKJWrRoEfS4/vrrJUmnTp0Kat+xY8dS67j++ut17tw5nT59uuad+f8aNmyo1q1bl6rV6/UqISGhVL1FRUVBtfbv3z/wMcDWrVvVo0cP9ejRQ/Hx8dq6dat8Pp8+/PBD9e/fP2gby5Yt04033qjo6Gg1b95cLVq00Lvvviuv11uqxpSUlKDnp0+f1nfffVfma9SpU6dK+9ykSRNJKnWthiSdP38+qA0QSbhmAHDAyJEj1b9/f61atUp//vOf9dRTT2nu3LlauXKlMjMzK1zW7/ere/fumjdvXpnzk5OTQ1Fypdxutxo0CP7/gt/vV0JCgpYvX17mMlf+L71fv35avHixPv/8c23dulX9+/eXy+VSv379tHXrViUlJcnv9weFgVdeeUXjxo3T8OHDNXXqVCUkJCgqKko5OTk6cuRIqe05fWCOj4+X2+3W8ePHS827PC0pKcnRbQJ1AWEAcEirVq300EMP6aGHHtKpU6d088036/HHHw+EgfJ+/a5Dhw768MMPNXDgwCr9Qt7lU+xXOnTokK655pqgg3EodOjQQevXr1ffvn0rPRBfPsivW7dOe/bs0fTp0yX97WLBhQsXKikpSTExMUEfebz11ltq3769Vq5cGfRaZGdnV6m+Fi1aqEmTJmW+RgcPHqx0+QYNGqh79+7au3dvqXm7du1S+/btuXgQEYmPCYAaKikpKXUKOyEhQUlJSUGnm2NiYso81T1y5Eh99dVXWrx4cal53333nc6ePRs0bceOHUGfnxcUFOjtt9/WoEGDFBUVVdPuVGjkyJEqKSnRY489VmrepUuXdObMmcDzlJQU/eAHP9Azzzyjixcvqm/fvpL+FhKOHDmit956S3//93+vhg3/7/8kl+s3V3wlcdeuXdqxY0eV6ouKilJGRoZWr16tL774IjD9s88+09q1a6u0jhEjRmjPnj1BgeDgwYN67733dNddd1VpHUB9w5kBoIYKCwvVunVrjRgxQqmpqWratKnWr1+vPXv26He/+12gXVpamt544w1NmTJFPXv2VNOmTTV06FCNGTNGK1as0IMPPqiNGzeqb9++Kikp0V/+8hetWLFCa9euVY8ePQLr6datmzIyMoK+WihJc+bMCarr+eef15kzZwIXNf73f/+3vvzyS0l/+86/x+Opdl9vvfVWPfDAA8rJydH+/fs1aNAgNWrUSHl5eXrzzTf1+9//XiNGjAi079+/v15//XV1795d1157rSTp5ptvVkxMjA4dOqSf//znQev/6U9/qpUrV+rOO+/UkCFDlJ+fr0WLFumGG25QUVFRlWqcM2eO1qxZo/79++uhhx7SpUuX9Nxzz6lr16766KOPKl3+oYce0uLFizVkyBD9+te/VqNGjTRv3jwlJibqkUceqcarBdQjtf11BqC+Ky4uNlOnTjWpqakmNjbWxMTEmNTU1MDX6i4rKioyP//5z02zZs2MpKCvGV64cMHMnTvXdO3a1bjdbnPttdeatLQ0M2fOHOP1egPtJJmsrCzzyiuvmI4dOxq3221uuukms3HjxlJ1tW3bNvBVxO8/8vPzK+zT2LFjTUxMTLnz//CHP5i0tDTTpEkTExsba7p3724effRRc+zYsaB2l7+ON2HChKDp6enpRpLZsGFD0HS/32+eeOIJ07Zt20Df3nnnHTN27Nig1+vyVwufeuqpMuvbvHmzSUtLM40bNzbt27c3ixYtMtnZ2ZV+tfCygoICM2LECBMXF2eaNm1qfvrTn5q8vLwqLQvURy5jrjgfB6BOc7lcysrK0vPPP1/bpQCIIFwzAACA5QgDAABYjjAAAIDl+DYBUI9wiQ+AUODMAAAAliMMAABguTr3MYHf79exY8cUGxtbpZ9mBQAAZTPGqLCwUElJSaXuNXKlOhcGjh07Vms3ZgEAIBIVFBSUugvplepcGLh8E5CCggLFxcXVcjUAANRfPp9PycnJld5gq86FgcsfDcTFxREGAABwQGUfu3MBIQAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYLWRhYsGCB2rVrp+joaPXu3Vu7d+8O1aYAAEANhCQMvPHGG5oyZYqys7OVm5ur1NRUZWRk6NSpU6HYHAAAqIGQhIF58+bpvvvu0/jx43XDDTdo0aJFuuaaa/Tyyy+HYnMAAKAGHA8DFy5c0AcffKD09PT/20iDBkpPT9eOHTtKtS8uLpbP5wt6AACA8HE8DHz99dcqKSlRYmJi0PTExESdOHGiVPucnBx5PJ7Ag/sSAAAQXrX+bYIZM2bI6/UGHgUFBbVdEgAAVnH83gTXXXedoqKidPLkyaDpJ0+eVMuWLUu1d7vdcrvdTpcBAACqyPEzA40bN1ZaWpo2bNgQmOb3+7Vhwwb16dPH6c0BAIAaCsldC6dMmaKxY8eqR48e6tWrl+bPn6+zZ89q/PjxodgcAACogZCEgbvvvlunT5/WrFmzdOLECf3whz/UmjVrSl1UCAAAap/LGGNqu4gr+Xw+eTweeb1excXF1XY5AADUW1U9ptb6twkAAEDtIgwAAGA5wgAAAJYjDAAAYDnCAAAAlgvJVwvrA5ertiuoH0L9XRPGAagd7Nt1Q135Ph9nBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALBcw9ouIFIZE/ptuFyh30YkCMdYAE5i364a3medw5kBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByjoeBnJwc9ezZU7GxsUpISNDw4cN18OBBpzcDAAAc4ngY2Lx5s7KysrRz506tW7dOFy9e1KBBg3T27FmnNwUAABzgMia0P+h4+vRpJSQkaPPmzfrRj35UaXufzyePxyOv16u4uLiQ1RXqn5iMlJ/JDHU/IqEPgNMiYb+IhD5I9f9YUdVjasjvTeD1eiVJ8fHxZc4vLi5WcXFx4LnP5wt1SQAA4AohvYDQ7/dr8uTJ6tu3r7p161Zmm5ycHHk8nsAjOTk5lCUBAIDvCenHBBMmTNCf/vQnbdu2Ta1bty6zTVlnBpKTk/mYoAoi4TRcJPQBcFok7BeR0Aep/h8rav1jgokTJ+qdd97Rli1byg0CkuR2u+V2u0NVBgAAqITjYcAYo4cfflirVq3Spk2blJKS4vQmAACAgxwPA1lZWXr11Vf19ttvKzY2VidOnJAkeTweNWnSxOnNAQCAGnL8mgFXOR+wLFmyROPGjat0eb5aWHWR8JlcJPQBcFok7BeR0Aep/h8rau2agRD/bAEAAHAY9yYAAMByhAEAACxHGAAAwHKEAQAALEcYAADAciG/UZGtwvG1mnCIhH5EQh8Ap0XCfhEJfagrODMAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYrmFtFxCpjAn9Nlyu0G8j1P2IhD4ATouE/SIS+iCFpx91AWcGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLhTwM/Pa3v5XL5dLkyZNDvSkAAHAVQhoG9uzZoxdffFE33nhjKDcDAABqIGRhoKioSKNHj9bixYt17bXXhmozAACghkIWBrKysjRkyBClp6dX2K64uFg+ny/oAQAAwickNyp6/fXXlZubqz179lTaNicnR3PmzAlFGQAAoAocPzNQUFCgX/3qV1q+fLmio6MrbT9jxgx5vd7Ao6CgwOmSAABABVzGOHsTyNWrV+vOO+9UVFRUYFpJSYlcLpcaNGig4uLioHnf5/P55PF45PV6FRcX52RpQUJ9W8pIubUmtzkFwi8S9otI6INU/48VVT2mOv4xwcCBA3XgwIGgaePHj1fnzp01bdq0CoMAAAAIP8fDQGxsrLp16xY0LSYmRs2bNy81HQAA1D5+gRAAAMuF5NsE37dp06ZwbAYAAFwFzgwAAGA5wgAAAJYjDAAAYDnCAAAAlgvLBYSov8LxwyGhFgl9iBgmDIPh4lemqoL9AlfizAAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGC5hrVdAK6eMbVdQf3gcoV+G4xFVYXhhQrxJvh7QiTizAAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYLmQhIGvvvpK//iP/6jmzZurSZMm6t69u/bu3RuKTQEAgBpy/BcIv/32W/Xt21cDBgzQn/70J7Vo0UJ5eXm69tprnd4UAABwgONhYO7cuUpOTtaSJUsC01JSUpzeDAAAcIjjHxP813/9l3r06KG77rpLCQkJuummm7R48eJy2xcXF8vn8wU9AABA+DgeBj7//HMtXLhQHTt21Nq1azVhwgRNmjRJy5YtK7N9Tk6OPB5P4JGcnOx0SQAAoAIuY5y9P1bjxo3Vo0cPvf/++4FpkyZN0p49e7Rjx45S7YuLi1VcXBx47vP5lJycLK/Xq7i4OCdLCxLqO49x17G6g7vMwUn8Pdmlvh8rfD6fPB5PpcdUx88MtGrVSjfccEPQtC5duuiLL74os73b7VZcXFzQAwAAhI/jYaBv3746ePBg0LRDhw6pbdu2Tm8KAAA4wPEw8M///M/auXOnnnjiCR0+fFivvvqq/vCHPygrK8vpTQEAAAc4HgZ69uypVatW6bXXXlO3bt302GOPaf78+Ro9erTTmwIAAA5w/ALCmqrqxQ41Vd8vCkHVccEXnMTfk13q+7Gi1i4gBAAA9QthAAAAyxEGAACwHGEAAADLEQYAALCc43ctxN+E44pjVBFXZqOe4f0D4caZAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACzXsLYLiFTG1HYFuMzlCsNGGG84iPePuiMs7x91AGcGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLOR4GSkpKNHPmTKWkpKhJkybq0KGDHnvsMRl+RQMAgDrJ8V8gnDt3rhYuXKhly5apa9eu2rt3r8aPHy+Px6NJkyY5vTkAAFBDjoeB999/X8OGDdOQIUMkSe3atdNrr72m3bt3O70pAADgAMc/Jrjlllu0YcMGHTp0SJL04Ycfatu2bcrMzCyzfXFxsXw+X9ADAACEj+NnBqZPny6fz6fOnTsrKipKJSUlevzxxzV69Ogy2+fk5GjOnDlOlwEAAKrI8TMDK1as0PLly/Xqq68qNzdXy5Yt09NPP61ly5aV2X7GjBnyer2BR0FBgdMlAQCACjh+ZmDq1KmaPn267rnnHklS9+7ddfToUeXk5Gjs2LGl2rvdbrndbqfLAAAAVeT4mYFz586pQYPg1UZFRcnv9zu9KQAA4ADHzwwMHTpUjz/+uNq0aaOuXbtq3759mjdvnu69916nNwUAABzgMg7/GlBhYaFmzpypVatW6dSpU0pKStKoUaM0a9YsNW7cuNLlfT6fPB6PvF6v4uLinCwtiMsVslVLkviNpboj1GMtMd424e/JLvX9WFHVY6rjYaCmCANwGm/ecBJ/T3ap78eKqh5TuTcBAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAlnP8dwYQPuG4qhlVw1jASfw9VQ3funAOZwYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLNaztAlC3GRPa9btcoV2/FPo+AE6LhP0iHH2AczgzAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYrtphYMuWLRo6dKiSkpLkcrm0evXqoPnGGM2aNUutWrVSkyZNlJ6erry8PKfqBQAADqt2GDh79qxSU1O1YMGCMuc/+eSTevbZZ7Vo0SLt2rVLMTExysjI0Pnz52tcLAAAcF61f444MzNTmZmZZc4zxmj+/Pn6t3/7Nw0bNkyS9Mc//lGJiYlavXq17rnnnlLLFBcXq7i4OPDc5/NVtyQAAFADjl4zkJ+frxMnTig9PT0wzePxqHfv3tqxY0eZy+Tk5Mjj8QQeycnJTpYEAAAq4WgYOHHihCQpMTExaHpiYmJg3vfNmDFDXq838CgoKHCyJAAAUIlav2uh2+2W2+2u7TIAALCWo2cGWrZsKUk6efJk0PSTJ08G5gEAgLrF0TCQkpKili1basOGDYFpPp9Pu3btUp8+fZzcFAAAcEi1PyYoKirS4cOHA8/z8/O1f/9+xcfHq02bNpo8ebL+/d//XR07dlRKSopmzpyppKQkDR8+3Mm6AQCAQ6odBvbu3asBAwYEnk+ZMkWSNHbsWC1dulSPPvqozp49q/vvv19nzpxRv379tGbNGkVHRztXNQAAcIzLGGNqu4gr+Xw+eTweeb1excXFhWw7LlfIVi1JCserGuo+SKHvRyT0AXBaJOwXkdAHqf4fK6p6TOXeBAAAWI4wAACA5QgDAABYjjAAAIDlav0XCCNVOC6eCYdI6Eck9AFwWiTsF2HpgyUXIHNmAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsFzD2i4gUhkT+m24XKHfRqj7EQl9AJwWCftFJPRBCkM/6sj7E2cGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLVTsMbNmyRUOHDlVSUpJcLpdWr14dmHfx4kVNmzZN3bt3V0xMjJKSkvSLX/xCx44dc7JmAADgoGqHgbNnzyo1NVULFiwoNe/cuXPKzc3VzJkzlZubq5UrV+rgwYO64447HCkWAAA4r9o/R5yZmanMzMwy53k8Hq1bty5o2vPPP69evXrpiy++UJs2ba6uSgAAEDIhvzeB1+uVy+VSs2bNypxfXFys4uLiwHOfzxfqkgAAwBVCegHh+fPnNW3aNI0aNUpxcXFltsnJyZHH4wk8kpOTQ1kSAAD4npCFgYsXL2rkyJEyxmjhwoXltpsxY4a8Xm/gUVBQEKqSAABAGULyMcHlIHD06FG999575Z4VkCS32y232x2KMgAAQBU4HgYuB4G8vDxt3LhRzZs3d3oTAADAQdUOA0VFRTp8+HDgeX5+vvbv36/4+Hi1atVKI0aMUG5urt555x2VlJToxIkTkqT4+Hg1btzYucoBAIAjXMYYU50FNm3apAEDBpSaPnbsWM2ePVspKSllLrdx40bddtttla7f5/PJ4/HI6/VW+PFCTblcIVu1JKl6r+rVCXUfpND3IxL6ADgtEvaLSOiDVP+PFVU9plb7zMBtt92mivJDNbMFAACoZdybAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMuF/EZFtgrH12oigVHoXyiXi2+4AJGI91nncGYAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyzWs7QJqizG1XQEkhWUgGGog/HiPrV84MwAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWK7aYWDLli0aOnSokpKS5HK5tHr16nLbPvjgg3K5XJo/f34NSgQAAKFU7TBw9uxZpaamasGCBRW2W7VqlXbu3KmkpKSrLg4AAIRetX+OODMzU5mZmRW2+eqrr/Twww9r7dq1GjJkyFUXBwAAQs/xexP4/X6NGTNGU6dOVdeuXSttX1xcrOLi4sBzn8/ndEkAAKACjl9AOHfuXDVs2FCTJk2qUvucnBx5PJ7AIzk52emSAABABRwNAx988IF+//vfa+nSpXK5XFVaZsaMGfJ6vYFHQUGBkyUBAIBKOBoGtm7dqlOnTqlNmzZq2LChGjZsqKNHj+qRRx5Ru3btylzG7XYrLi4u6AEAAMLH0WsGxowZo/T09KBpGRkZGjNmjMaPH+/kpgAAgEOqHQaKiop0+PDhwPP8/Hzt379f8fHxatOmjZo3bx7UvlGjRmrZsqU6depU82oBAIDjqh0G9u7dqwEDBgSeT5kyRZI0duxYLV261LHCAABAeFQ7DNx2220yxlS5/V//+tfqbgIAAIQR9yYAAMByhAEAACxHGAAAwHKEAQAALOf4vQlq6vLFidyjAACAmrl8LK3swv86FwYKCwsliXsUAADgkMLCQnk8nnLnu0x1vicYBn6/X8eOHVNsbGyV72/g8/mUnJysgoICa37O2MY+S3b228Y+S/Tbpn7b2GcpPP02xqiwsFBJSUlq0KD8KwPq3JmBBg0aqHXr1le1rI33NrCxz5Kd/baxzxL9tomNfZZC3++KzghcxgWEAABYjjAAAIDlIiIMuN1uZWdny+1213YpYWNjnyU7+21jnyX6bVO/beyzVLf6XecuIAQAAOEVEWcGAADA1SMMAABgOcIAAACWIwwAAGA5wgAAAJarN2FgwYIFateunaKjo9W7d2/t3r27wvZvvvmmOnfurOjoaHXv3l3/8z//E6ZKay4nJ0c9e/ZUbGysEhISNHz4cB08eLDCZZYuXSqXyxX0iI6ODlPFzpg9e3apPnTu3LnCZerzOF/Wrl27Uv12uVzKysoqs319HOstW7Zo6NChSkpKksvl0urVq4PmG2M0a9YstWrVSk2aNFF6erry8vIqXW913xfCraJ+X7x4UdOmTVP37t0VExOjpKQk/eIXv9CxY8cqXOfV7CfhVNlYjxs3rlT9gwcPrnS99XmsJZW5j7tcLj311FPlrjOcY10vwsAbb7yhKVOmKDs7W7m5uUpNTVVGRoZOnTpVZvv3339fo0aN0i9/+Uvt27dPw4cP1/Dhw/Xxxx+HufKrs3nzZmVlZWnnzp1at26dLl68qEGDBuns2bMVLhcXF6fjx48HHkePHg1Txc7p2rVrUB+2bdtWbtv6Ps6X7dmzJ6jP69atkyTddddd5S5T38b67NmzSk1N1YIFC8qc/+STT+rZZ5/VokWLtGvXLsXExCgjI0Pnz58vd53VfV+oDRX1+9y5c8rNzdXMmTOVm5urlStX6uDBg7rjjjsqXW919pNwq2ysJWnw4MFB9b/22msVrrO+j7WkoP4eP35cL7/8slwul372s59VuN6wjbWpB3r16mWysrICz0tKSkxSUpLJyckps/3IkSPNkCFDgqb17t3bPPDAAyGtM1ROnTplJJnNmzeX22bJkiXG4/GEr6gQyM7ONqmpqVVuH2njfNmvfvUr06FDB+P3+8ucX9/HWpJZtWpV4Lnf7zctW7Y0Tz31VGDamTNnjNvtNq+99lq566nu+0Jt+36/y7J7924jyRw9erTcNtXdT2pTWX0eO3asGTZsWLXWE4ljPWzYMHP77bdX2CacY13nzwxcuHBBH3zwgdLT0wPTGjRooPT0dO3YsaPMZXbs2BHUXpIyMjLKbV/Xeb1eSVJ8fHyF7YqKitS2bVslJydr2LBh+uSTT8JRnqPy8vKUlJSk9u3ba/To0friiy/KbRtp4yz97e/9lVde0b333lvhXTsjYawvy8/P14kTJ4LG0uPxqHfv3uWO5dW8L9QHXq9XLpdLzZo1q7BddfaTumjTpk1KSEhQp06dNGHCBH3zzTflto3EsT558qTeffdd/fKXv6y0bbjGus6Hga+//lolJSVKTEwMmp6YmKgTJ06UucyJEyeq1b4u8/v9mjx5svr27atu3bqV265Tp056+eWX9fbbb+uVV16R3+/XLbfcoi+//DKM1dZM7969tXTpUq1Zs0YLFy5Ufn6++vfvr8LCwjLbR9I4X7Z69WqdOXNG48aNK7dNJIz1lS6PV3XG8mreF+q68+fPa9q0aRo1alSFd7Cr7n5S1wwePFh//OMftWHDBs2dO1ebN29WZmamSkpKymwfiWO9bNkyxcbG6h/+4R8qbBfOsa5ztzBGsKysLH388ceVfk7Up08f9enTJ/D8lltuUZcuXfTiiy/qscceC3WZjsjMzAz8+8Ybb1Tv3r3Vtm1brVixokoJOhK89NJLyszMVFJSUrltImGsEezixYsaOXKkjDFauHBhhW3r+35yzz33BP7dvXt33XjjjerQoYM2bdqkgQMH1mJl4fPyyy9r9OjRlV74G86xrvNnBq677jpFRUXp5MmTQdNPnjypli1blrlMy5Ytq9W+rpo4caLeeecdbdy4Ua1bt67Wso0aNdJNN92kw4cPh6i60GvWrJmuv/76cvsQKeN82dGjR7V+/Xr90z/9U7WWq+9jfXm8qjOWV/O+UFddDgJHjx7VunXrqn1f+8r2k7quffv2uu6668qtP5LGWpK2bt2qgwcPVns/l0I71nU+DDRu3FhpaWnasGFDYJrf79eGDRuC/nd0pT59+gS1l6R169aV276uMcZo4sSJWrVqld577z2lpKRUex0lJSU6cOCAWrVqFYIKw6OoqEhHjhwptw/1fZy/b8mSJUpISNCQIUOqtVx9H+uUlBS1bNkyaCx9Pp927dpV7lhezftCXXQ5COTl5Wn9+vVq3rx5tddR2X5S13355Zf65ptvyq0/Usb6spdeeklpaWlKTU2t9rIhHeuwXKZYQ6+//rpxu91m6dKl5tNPPzX333+/adasmTlx4oQxxpgxY8aY6dOnB9pv377dNGzY0Dz99NPms88+M9nZ2aZRo0bmwIEDtdWFapkwYYLxeDxm06ZN5vjx44HHuXPnAm2+3+c5c+aYtWvXmiNHjpgPPvjA3HPPPSY6Otp88skntdGFq/LII4+YTZs2mfz8fLN9+3aTnp5urrvuOnPq1CljTOSN85VKSkpMmzZtzLRp00rNi4SxLiwsNPv27TP79u0zksy8efPMvn37AlfN//a3vzXNmjUzb7/9tvnoo4/MsGHDTEpKivnuu+8C67j99tvNc889F3he2ftCXVBRvy9cuGDuuOMO07p1a7N///6gfb24uDiwju/3u7L9pLZV1OfCwkLz61//2uzYscPk5+eb9evXm5tvvtl07NjRnD9/PrCOSBvry7xer7nmmmvMwoULy1xHbY51vQgDxhjz3HPPmTZt2pjGjRubXr16mZ07dwbm3XrrrWbs2LFB7VesWGGuv/5607hxY9O1a1fz7rvvhrniqyepzMeSJUsCbb7f58mTJwden8TERPOTn/zE5Obmhr/4Grj77rtNq1atTOPGjc0PfvADc/fdd5vDhw8H5kfaOF9p7dq1RpI5ePBgqXmRMNYbN24s82/6cr/8fr+ZOXOmSUxMNG632wwcOLDUa9G2bVuTnZ0dNK2i94W6oKJ+5+fnl7uvb9y4MbCO7/e7sv2ktlXU53PnzplBgwaZFi1amEaNGpm2bdua++67r9RBPdLG+rIXX3zRNGnSxJw5c6bMddTmWLuMMcb58w0AAKC+qPPXDAAAgNAiDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACW+3/Z5kUUm4qJQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-198f7f9da969>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCXc4UpVjPco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actor Critic on MiniPacman"
      ],
      "metadata": {
        "id": "33mU9NeNjTeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd"
      ],
      "metadata": {
        "id": "uKzedwL-jW5x"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "A9Y5jqewja90"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ],
      "metadata": {
        "id": "0vZS1WmbjePh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OnPolicy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OnPolicy, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def act(self, x, deterministic=False):\n",
        "        logit, value = self.forward(x)\n",
        "        probs = F.softmax(logit)\n",
        "\n",
        "        if deterministic:\n",
        "            action = probs.max(1)[1]\n",
        "        else:\n",
        "            action = probs.multinomial(num_samples=1)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def evaluate_actions(self, x, action):\n",
        "        logit, value = self.forward(x)\n",
        "\n",
        "        probs     = F.softmax(logit)\n",
        "        log_probs = F.log_softmax(logit)\n",
        "\n",
        "        action_log_probs = log_probs.gather(1, action)\n",
        "        entropy = -(probs * log_probs).sum(1).mean()\n",
        "\n",
        "        return logit, action_log_probs, value, entropy"
      ],
      "metadata": {
        "id": "vJAy5fLUjiAB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActorCritic(OnPolicy):\n",
        "    def __init__(self, in_shape, num_actions):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.in_shape = in_shape\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0], 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.feature_size(), 256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.critic  = nn.Linear(256, 1)\n",
        "        self.actor   = nn.Linear(256, num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        logit = self.actor(x)\n",
        "        value = self.critic(x)\n",
        "        return logit, value\n",
        "\n",
        "    def feature_size(self):\n",
        "        return self.features(autograd.Variable(torch.zeros(1, *self.in_shape))).view(1, -1).size(1)"
      ],
      "metadata": {
        "id": "WiDybwMpjmLR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RolloutStorage(object):\n",
        "    def __init__(self, num_steps, num_envs, state_shape):\n",
        "        self.num_steps = num_steps\n",
        "        self.num_envs  = num_envs\n",
        "        self.states  = torch.zeros(num_steps + 1, num_envs, *state_shape)\n",
        "        self.rewards = torch.zeros(num_steps,     num_envs, 1)\n",
        "        self.masks   = torch.ones(num_steps  + 1, num_envs, 1)\n",
        "        self.actions = torch.zeros(num_steps,     num_envs, 1).long()\n",
        "        self.use_cuda = False\n",
        "\n",
        "    def cuda(self):\n",
        "        self.use_cuda  = True\n",
        "        self.states    = self.states.cuda()\n",
        "        self.rewards   = self.rewards.cuda()\n",
        "        self.masks     = self.masks.cuda()\n",
        "        self.actions   = self.actions.cuda()\n",
        "\n",
        "    def insert(self, step, state, action, reward, mask):\n",
        "        self.states[step + 1].copy_(state)\n",
        "        self.actions[step].copy_(action)\n",
        "        self.rewards[step].copy_(reward)\n",
        "        self.masks[step + 1].copy_(mask)\n",
        "\n",
        "    def after_update(self):\n",
        "        self.states[0].copy_(self.states[-1])\n",
        "        self.masks[0].copy_(self.masks[-1])\n",
        "\n",
        "    def compute_returns(self, next_value, gamma):\n",
        "        returns   = torch.zeros(self.num_steps + 1, self.num_envs, 1)\n",
        "        if self.use_cuda:\n",
        "            returns = returns.cuda()\n",
        "        returns[-1] = next_value\n",
        "        for step in reversed(range(self.num_steps)):\n",
        "            returns[step] = returns[step + 1] * gamma * self.masks[step + 1] + self.rewards[step]\n",
        "        return returns[:-1]"
      ],
      "metadata": {
        "id": "gNI5Quyxjqwx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "\n",
        "state_shape = envs.observation_space.shape"
      ],
      "metadata": {
        "id": "d2WNiy8AjvFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacf85f5-fe8b-41e3-eda3-28dd104edb67"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#a2c hyperparams:\n",
        "gamma = 0.99\n",
        "entropy_coef = 0.01\n",
        "value_loss_coef = 0.5\n",
        "max_grad_norm = 0.5\n",
        "num_steps = 5\n",
        "num_frames = int(10e2)\n",
        "\n",
        "#rmsprop hyperparams:\n",
        "lr    = 7e-4\n",
        "eps   = 1e-5\n",
        "alpha = 0.99\n",
        "\n",
        "#Init a2c and rmsprop\n",
        "actor_critic = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "optimizer = optim.RMSprop(actor_critic.parameters(), lr, eps=eps, alpha=alpha)\n",
        "\n",
        "if USE_CUDA:\n",
        "    actor_critic = actor_critic.cuda()"
      ],
      "metadata": {
        "id": "4wAoXptjl6UA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rollout = RolloutStorage(num_steps, num_envs, envs.observation_space.shape)\n",
        "#rollout.cuda()\n",
        "\n",
        "all_rewards = []\n",
        "all_losses  = []"
      ],
      "metadata": {
        "id": "dfQmiVC2l-48"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = envs.reset()\n",
        "state = torch.FloatTensor(np.float32(state))\n",
        "\n",
        "rollout.states[0].copy_(state)\n",
        "\n",
        "episode_rewards = torch.zeros(num_envs, 1)\n",
        "final_rewards   = torch.zeros(num_envs, 1)\n",
        "\n",
        "for i_update in range(num_frames):\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        action = actor_critic.act(Variable(state))\n",
        "\n",
        "        next_state, reward, done, _ = envs.step(action.squeeze(1).cpu().data.numpy())\n",
        "\n",
        "        reward = torch.FloatTensor(reward).unsqueeze(1)\n",
        "        episode_rewards += reward\n",
        "        masks = torch.FloatTensor(1-np.array(done)).unsqueeze(1)\n",
        "        final_rewards *= masks\n",
        "        final_rewards += (1-masks) * episode_rewards\n",
        "        episode_rewards *= masks\n",
        "\n",
        "        if USE_CUDA:\n",
        "            masks = masks.cuda()\n",
        "\n",
        "        state = torch.FloatTensor(np.float32(next_state))\n",
        "        rollout.insert(step, state, action.data, reward, masks)\n",
        "\n",
        "\n",
        "    _, next_value = actor_critic(Variable(rollout.states[-1], volatile=True))\n",
        "    next_value = next_value.data\n",
        "\n",
        "    returns = rollout.compute_returns(next_value, gamma)\n",
        "\n",
        "    logit, action_log_probs, values, entropy = actor_critic.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    values = values.view(num_steps, num_envs, 1)\n",
        "    action_log_probs = action_log_probs.view(num_steps, num_envs, 1)\n",
        "    advantages = Variable(returns) - values\n",
        "\n",
        "    value_loss = advantages.pow(2).mean()\n",
        "    action_loss = -(Variable(advantages.data) * action_log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = value_loss * value_loss_coef + action_loss - entropy * entropy_coef\n",
        "    loss=loss.unsqueeze(0)\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm(actor_critic.parameters(), max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    if i_update % 100 == 0:\n",
        "        all_rewards.append(final_rewards.mean())\n",
        "        all_losses.append(loss.data[0])\n",
        "\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('epoch %s. reward: %s' % (i_update, np.mean(all_rewards[-10:])))\n",
        "        plt.plot(all_rewards)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss %s' % all_losses[-1])\n",
        "        #plt.plot(all_losses)\n",
        "        # Convert the CUDA tensor to a NumPy array\n",
        "        numpy_all_losses = all_losses[-1].cpu().numpy()\n",
        "\n",
        "        # Plot the NumPy array\n",
        "        plt.plot(numpy_all_losses)\n",
        "        plt.show()\n",
        "\n",
        "    rollout.after_update()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2upgMAnGmBuS",
        "outputId": "ad24bc89-e2e1-4145-e4b0-26504fc28695"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(actor_critic.state_dict(), \"actor_critic_\" + mode)"
      ],
      "metadata": {
        "id": "_6hRG69TsYCC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def displayImage(image, step, reward):\n",
        "    clear_output(True)\n",
        "    s = \"step: \" + str(step) + \" reward: \" + str(reward)\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    time.sleep(0.1)"
      ],
      "metadata": {
        "id": "mw_1FJgXoWkA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = MiniPacman(mode, 1000)\n",
        "\n",
        "done = False\n",
        "state = env.reset()\n",
        "total_reward = 0\n",
        "step   = 1\n",
        "\n",
        "\n",
        "while not done:\n",
        "    current_state = torch.FloatTensor(state).unsqueeze(0)\n",
        "    if USE_CUDA:\n",
        "        current_state = current_state.cuda()\n",
        "\n",
        "    action = actor_critic.act(Variable(current_state))\n",
        "\n",
        "    next_state, reward, done, _ = env.step(action.data[0, 0])\n",
        "    total_reward += reward\n",
        "    state = next_state\n",
        "\n",
        "    image = torch.FloatTensor(state).permute(1, 2, 0).cpu().numpy()\n",
        "    displayImage(image, step, total_reward)\n",
        "    step += 1"
      ],
      "metadata": {
        "id": "BRC9uBW1sf2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d715cd70-7f40-44de-952a-8285c63dc86a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KK8oou8U1wRN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Environment Model\n",
        "The Environment model is passed the current state, action (using the actor critic model) and is used to predict the next state (as an image) and the associated reward. We compare this to the ground truth by simultaneously running the actor critic model."
      ],
      "metadata": {
        "id": "O57srqFSskiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "metadata": {
        "id": "v2MpY_dC12fH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "FyjbKonY17FH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ],
      "metadata": {
        "id": "bvdmi7Tp1_AP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7 different pixels in MiniPacman\n",
        "pixels = (\n",
        "    (0.0, 1.0, 1.0),\n",
        "    (0.0, 1.0, 0.0),\n",
        "    (0.0, 0.0, 1.0),\n",
        "    (1.0, 1.0, 1.0),\n",
        "    (1.0, 1.0, 0.0),\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (1.0, 0.0, 0.0),\n",
        ")\n",
        "pixel_to_categorical = {pix:i for i, pix in enumerate(pixels)}\n",
        "num_pixels = len(pixels)\n",
        "\n",
        "#For each mode in MiniPacman there are different rewards\n",
        "mode_rewards = {\n",
        "    \"regular\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"avoid\":   [0.1, -0.1, -5, -10, -20],\n",
        "    \"hunt\":    [0, 1, 10, -20],\n",
        "    \"ambush\":  [0, -0.1, 10, -20],\n",
        "    \"rush\":    [0, -0.1, 9.9]\n",
        "}\n",
        "reward_to_categorical = {mode: {reward:i for i, reward in enumerate(mode_rewards[mode])} for mode in mode_rewards.keys()}"
      ],
      "metadata": {
        "id": "4L8nLzuL2J-V"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pix_to_target(next_states):\n",
        "    target = []\n",
        "    for pixel in next_states.transpose(0, 2, 3, 1).reshape(-1, 3):\n",
        "        target.append(pixel_to_categorical[tuple([np.ceil(pixel[0]), np.ceil(pixel[1]), np.ceil(pixel[2])])])\n",
        "    return target\n",
        "\n",
        "def target_to_pix(imagined_states):\n",
        "    pixels = []\n",
        "    to_pixel = {value: key for key, value in pixel_to_categorical.items()}\n",
        "    for target in imagined_states:\n",
        "        pixels.append(list(to_pixel[target]))\n",
        "    return np.array(pixels)\n",
        "\n",
        "def rewards_to_target(mode, rewards):\n",
        "    target = []\n",
        "    for reward in rewards:\n",
        "        target.append(reward_to_categorical[mode][reward])\n",
        "    return target\n",
        "\n",
        "def plot(frame_idx, rewards, losses):\n",
        "    clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('loss %s' % losses[-1])\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "\n",
        "def displayImage(image, step, reward):\n",
        "    s = str(step) + \" \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "m0NjZ_xn2OLj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_shape, n1, n2, n3):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        self.in_shape = in_shape\n",
        "        self.n1 = n1\n",
        "        self.n2 = n2\n",
        "        self.n3 = n3\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=in_shape[1:])\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0] * 2, n1, kernel_size=1, stride=2, padding=6),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n1, n1, kernel_size=10, stride=1, padding=(5, 6)),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0] * 2, n2, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(n2, n2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(n1 + n2,  n3, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.pool_and_inject(inputs)\n",
        "        x = torch.cat([self.conv1(x), self.conv2(x)], 1)\n",
        "        x = self.conv3(x)\n",
        "        x = torch.cat([x, inputs], 1)\n",
        "        return x\n",
        "\n",
        "    def pool_and_inject(self, x):\n",
        "        pooled     = self.maxpool(x)\n",
        "        tiled      = pooled.expand((x.size(0),) + self.in_shape)\n",
        "        out        = torch.cat([tiled, x], 1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "M-oC69pa2ZJ1"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EnvModel(nn.Module):\n",
        "    def __init__(self, in_shape, num_pixels, num_rewards):\n",
        "        super(EnvModel, self).__init__()\n",
        "\n",
        "        width  = in_shape[1]\n",
        "        height = in_shape[2]\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(8, 64, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.basic_block1 = BasicBlock((64, width, height), 16, 32, 64)\n",
        "        self.basic_block2 = BasicBlock((128, width, height), 16, 32, 64)\n",
        "\n",
        "        self.image_conv = nn.Sequential(\n",
        "            nn.Conv2d(192, 256, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.image_fc = nn.Linear(256, num_pixels)\n",
        "\n",
        "        self.reward_conv = nn.Sequential(\n",
        "            nn.Conv2d(192, 64, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.reward_fc    = nn.Linear(64 * width * height, num_rewards)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        print(inputs.shape)\n",
        "        x = self.conv(inputs)\n",
        "        x = self.basic_block1(x)\n",
        "        x = self.basic_block2(x)\n",
        "\n",
        "        image = self.image_conv(x)\n",
        "        image = image.permute(0, 2, 3, 1).contiguous().view(-1, 256)\n",
        "        image = self.image_fc(image)\n",
        "\n",
        "        reward = self.reward_conv(x)\n",
        "        reward = reward.view(batch_size, -1)\n",
        "        reward = self.reward_fc(reward)\n",
        "\n",
        "        return image, reward"
      ],
      "metadata": {
        "id": "BIvma_lz2c0p"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n"
      ],
      "metadata": {
        "id": "v5CMYRql2hG4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_model    = EnvModel(envs.observation_space.shape, num_pixels, len(mode_rewards[\"regular\"]))\n",
        "actor_critic = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(env_model.parameters())\n",
        "\n",
        "if USE_CUDA:\n",
        "    env_model    = env_model.cuda()\n",
        "    actor_critic = actor_critic.cuda()"
      ],
      "metadata": {
        "id": "cgGeq3Ar2kpL"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "actor_critic.load_state_dict(torch.load(\"actor_critic_\" + mode))\n",
        "def get_action(state):\n",
        "    if state.ndim == 4:\n",
        "        state = torch.FloatTensor(np.float32(state))\n",
        "    else:\n",
        "        state = torch.FloatTensor(np.float32(state)).unsqueeze(0)\n",
        "\n",
        "    action = actor_critic.act(Variable(state, volatile=True))\n",
        "    action = action.data.cpu().squeeze(1).numpy()\n",
        "    return action\n",
        "def play_games(envs, frames):\n",
        "    states = envs.reset()\n",
        "\n",
        "    for frame_idx in range(frames):\n",
        "        actions = get_action(states)\n",
        "        next_states, rewards, dones, _ = envs.step(actions)\n",
        "\n",
        "        yield frame_idx, states, actions, rewards, next_states, dones\n",
        "\n",
        "        states = next_states"
      ],
      "metadata": {
        "id": "pj29EFRv2nuV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the training loop, as you can see we pass the current state concantenated with one hot encoded action to the model. The output of the model is an image of the next state and the reward. This is compared to the target, reward to train the model-"
      ],
      "metadata": {
        "id": "i19laUCCo2LK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reward_coef = 0.1\n",
        "num_updates = 5000\n",
        "\n",
        "losses = []\n",
        "all_rewards = []\n",
        "\n",
        "for frame_idx, states, actions, rewards, next_states, dones in play_games(envs, num_updates):\n",
        "    states      = torch.FloatTensor(states)\n",
        "    actions     = torch.LongTensor(actions)\n",
        "\n",
        "    batch_size = states.size(0)\n",
        "\n",
        "    onehot_actions = torch.zeros(batch_size, num_actions, *state_shape[1:])\n",
        "    onehot_actions[range(batch_size), actions] = 1\n",
        "    inputs = Variable(torch.cat([states, onehot_actions], 1))\n",
        "\n",
        "    if USE_CUDA:\n",
        "        inputs = inputs.cuda()\n",
        "\n",
        "    imagined_state, imagined_reward = env_model(inputs)\n",
        "\n",
        "    target_state = pix_to_target(next_states)\n",
        "    target_state = Variable(torch.LongTensor(target_state))\n",
        "\n",
        "    target_reward = rewards_to_target(mode, rewards)\n",
        "    target_reward = Variable(torch.LongTensor(target_reward))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    image_loss  = criterion(imagined_state, target_state)\n",
        "    reward_loss = criterion(imagined_reward, target_reward)\n",
        "    loss = image_loss + reward_coef * reward_loss\n",
        "    loss.backward()\n",
        "    loss=loss.unsqueeze(0)\n",
        "    loss=loss.cpu()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.data[0])\n",
        "    all_rewards.append(np.mean(rewards))\n",
        "    if frame_idx % 10 == 0:\n",
        "        plot(frame_idx, all_rewards,losses)"
      ],
      "metadata": {
        "id": "AH2_1c4Q2wKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "8231ce96-f953-4b1b-e037-0d6932ae9622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n",
            "torch.Size([16, 8, 15, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(env_model.state_dict(), \"env_model_\" + mode)"
      ],
      "metadata": {
        "id": "719fCHrx22sv"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QLVEzSjKhNSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you can see the comparision of the imagined state to the ground truth after training the model sufficiently"
      ],
      "metadata": {
        "id": "BI1fLCX5pRwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "env = MiniPacman(mode, 1000)\n",
        "batch_size = 1\n",
        "\n",
        "done = False\n",
        "state = env.reset()\n",
        "iss = []\n",
        "ss  = []\n",
        "\n",
        "steps = 0\n",
        "\n",
        "while not done:\n",
        "    steps += 1\n",
        "    actions = get_action(state)\n",
        "    onehot_actions = torch.zeros(batch_size, num_actions, *state_shape[1:])\n",
        "    onehot_actions[range(batch_size), actions] = 1\n",
        "    state = torch.FloatTensor(state).unsqueeze(0)\n",
        "\n",
        "    inputs = Variable(torch.cat([state, onehot_actions], 1))\n",
        "    if USE_CUDA:\n",
        "        inputs = inputs.cuda()\n",
        "\n",
        "    imagined_state, imagined_reward = env_model(inputs)\n",
        "    imagined_state = F.softmax(imagined_state)\n",
        "    iss.append(imagined_state)\n",
        "\n",
        "    next_state, reward, done, _ = env.step(actions[0])\n",
        "    ss.append(state)\n",
        "    state = next_state\n",
        "\n",
        "    imagined_image = target_to_pix(imagined_state.view(batch_size, -1, len(pixels))[0].max(1)[1].data.cpu().numpy())\n",
        "    imagined_image = imagined_image.reshape(15, 19, 3)\n",
        "    state_image = torch.FloatTensor(next_state).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    clear_output()\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(131)\n",
        "    plt.title(\"Imagined\")\n",
        "    plt.imshow(imagined_image)\n",
        "    plt.subplot(132)\n",
        "    plt.title(\"Actual\")\n",
        "    plt.imshow(state_image)\n",
        "    plt.show()\n",
        "    time.sleep(0.3)\n",
        "\n",
        "    if steps > 30:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "bmAG7S2q38-n",
        "outputId": "220cedcd-60c5-41f2-fbbc-30b1f524035e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imagination Augmented Agent\n",
        "This is the implementation of the original imagination augmented agent as given in the paper. It uses the above environment model in its imagination core to generate imagined state, rewards. Note that the model takes a lot of time and resource to train sufficiently"
      ],
      "metadata": {
        "id": "HISkwy1Y4aR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
      ],
      "metadata": {
        "id": "Uq8tMa2l4ilT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixels = (\n",
        "    (0.0, 1.0, 0.0),\n",
        "    (0.0, 1.0, 1.0),\n",
        "    (0.0, 0.0, 1.0),\n",
        "    (1.0, 1.0, 1.0),\n",
        "    (1.0, 1.0, 0.0),\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (1.0, 0.0, 0.0)\n",
        ")\n",
        "pixel_to_onehot = {pix:i for i, pix in enumerate(pixels)}\n",
        "num_pixels = len(pixels)\n",
        "\n",
        "task_rewards = {\n",
        "    \"regular\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"avoid\":   [0.1, -0.1, -5, -10, -20],\n",
        "    \"hunt\":    [0, 1, 10, -20],\n",
        "    \"ambush\":  [0, -0.1, 10, -20],\n",
        "    \"rush\":    [0, -0.1, 9.9]\n",
        "}\n",
        "reward_to_onehot = {mode: {reward:i for i, reward in enumerate(task_rewards[mode])} for mode in task_rewards.keys()}\n",
        "\n",
        "def pix_to_target(next_states):\n",
        "    target = []\n",
        "    for pixel in next_states.transpose(0, 2, 3, 1).reshape(-1, 3):\n",
        "        target.append(pixel_to_onehot[tuple([np.round(pixel[0]), np.round(pixel[1]), np.round(pixel[2])])])\n",
        "    return target\n",
        "\n",
        "def target_to_pix(imagined_states):\n",
        "    pixels = []\n",
        "    to_pixel = {value: key for key, value in pixel_to_onehot.items()}\n",
        "    for target in imagined_states:\n",
        "        #print(target)\n",
        "        pixels.append(list(to_pixel[target]))\n",
        "    return np.array(pixels)\n",
        "\n",
        "def rewards_to_target(mode, rewards):\n",
        "    target = []\n",
        "    for reward in rewards:\n",
        "        target.append(reward_to_onehot[mode][reward])\n",
        "    return target\n",
        "\n",
        "def displayImage(image, step, reward):\n",
        "    s = str(step) + \" \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "uHBtVtzc5NKE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n\n",
        "num_rewards = len(task_rewards[mode])"
      ],
      "metadata": {
        "id": "_0Qmj32R5ikE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RolloutEncoder(nn.Module):\n",
        "    def __init__(self, in_shape, num_rewards, hidden_size):\n",
        "        super(RolloutEncoder, self).__init__()\n",
        "\n",
        "        self.in_shape = in_shape\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0], 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.gru = nn.GRU(self.feature_size() + num_rewards, hidden_size)\n",
        "\n",
        "    def forward(self, state, reward):\n",
        "        num_steps  = state.size(0)\n",
        "        batch_size = state.size(1)\n",
        "\n",
        "        state = state.view(-1, *self.in_shape)\n",
        "        state = self.features(state)\n",
        "        state = state.view(num_steps, batch_size, -1)\n",
        "        rnn_input = torch.cat([state, reward], 2)\n",
        "        _, hidden = self.gru(rnn_input)\n",
        "        return hidden.squeeze(0)\n",
        "\n",
        "\n",
        "    def feature_size(self):\n",
        "        return self.features(autograd.Variable(torch.zeros(1, *self.in_shape))).view(1, -1).size(1)"
      ],
      "metadata": {
        "id": "0Vg0LgRe5mPX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class I2A(OnPolicy):\n",
        "    def __init__(self, in_shape, num_actions, num_rewards, hidden_size, imagination, full_rollout=True):\n",
        "        super(I2A, self).__init__()\n",
        "\n",
        "        self.in_shape      = in_shape\n",
        "        self.num_actions   = num_actions\n",
        "        self.num_rewards   = num_rewards\n",
        "\n",
        "        self.imagination = imagination\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_shape[0], 16, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.encoder = RolloutEncoder(in_shape, num_rewards, hidden_size)\n",
        "\n",
        "        if full_rollout:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(self.feature_size() + num_actions * hidden_size, 256),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "        else:\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(self.feature_size() + hidden_size, 256),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "\n",
        "        self.critic  = nn.Linear(256, 1)\n",
        "        self.actor   = nn.Linear(256, num_actions)\n",
        "\n",
        "    def forward(self, state):\n",
        "        batch_size = state.size(0)\n",
        "\n",
        "        imagined_state, imagined_reward = self.imagination(state.data)\n",
        "        hidden = self.encoder(Variable(imagined_state), Variable(imagined_reward))\n",
        "        hidden = hidden.view(batch_size, -1)\n",
        "\n",
        "        state = self.features(state)\n",
        "        state = state.view(state.size(0), -1)\n",
        "\n",
        "        x = torch.cat([state, hidden], 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        logit = self.actor(x)\n",
        "        value = self.critic(x)\n",
        "\n",
        "        return logit, value\n",
        "\n",
        "    def feature_size(self):\n",
        "        return self.features(autograd.Variable(torch.zeros(1, *self.in_shape))).view(1, -1).size(1)"
      ],
      "metadata": {
        "id": "2cQYfe0X5uIp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImaginationCore(object):\n",
        "    def __init__(self, num_rolouts, in_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=True):\n",
        "        self.num_rolouts  = num_rolouts\n",
        "        self.in_shape      = in_shape\n",
        "        self.num_actions   = num_actions\n",
        "        self.num_rewards   = num_rewards\n",
        "        self.env_model     = env_model\n",
        "        self.distil_policy = distil_policy\n",
        "        self.full_rollout  = full_rollout\n",
        "\n",
        "    def __call__(self, state):\n",
        "        state      = state.cpu()\n",
        "        batch_size = state.size(0)\n",
        "\n",
        "        rollout_states  = []\n",
        "        rollout_rewards = []\n",
        "\n",
        "        if self.full_rollout:\n",
        "            state = state.unsqueeze(0).repeat(self.num_actions, 1, 1, 1, 1).view(-1, *self.in_shape)\n",
        "            action = torch.LongTensor([[i] for i in range(self.num_actions)]*batch_size)\n",
        "            action = action.view(-1)\n",
        "            rollout_batch_size = batch_size * self.num_actions\n",
        "        else:\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "            rollout_batch_size = batch_size\n",
        "\n",
        "        for step in range(self.num_rolouts):\n",
        "            onehot_action = torch.zeros(rollout_batch_size, self.num_actions, *self.in_shape[1:])\n",
        "            onehot_action[range(rollout_batch_size), action] = 1\n",
        "            inputs = torch.cat([state, onehot_action], 1)\n",
        "\n",
        "            imagined_state, imagined_reward = self.env_model(Variable(inputs, volatile=True))\n",
        "\n",
        "            imagined_state  = F.softmax(imagined_state).max(1)[1].data.cpu()\n",
        "            #print(type(imagined_state))\n",
        "            imagined_reward = F.softmax(imagined_reward).max(1)[1].data.cpu()\n",
        "\n",
        "            imagined_state = target_to_pix(imagined_state.numpy())\n",
        "            imagined_state = torch.FloatTensor(imagined_state).view(rollout_batch_size, *self.in_shape)\n",
        "\n",
        "            onehot_reward = torch.zeros(rollout_batch_size, self.num_rewards)\n",
        "            onehot_reward[range(rollout_batch_size), imagined_reward] = 1\n",
        "\n",
        "            rollout_states.append(imagined_state.unsqueeze(0))\n",
        "            rollout_rewards.append(onehot_reward.unsqueeze(0))\n",
        "\n",
        "            state  = imagined_state\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "\n",
        "        return torch.cat(rollout_states), torch.cat(rollout_rewards)"
      ],
      "metadata": {
        "id": "SBc-lvRW5yQe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_rollout = True"
      ],
      "metadata": {
        "id": "QXgfMEUj5zp4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_model     = EnvModel(envs.observation_space.shape, num_pixels, num_rewards)\n",
        "env_model.load_state_dict(torch.load(\"env_model_\" + mode))\n",
        "\n",
        "distil_policy = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "distil_optimizer = optim.Adam(distil_policy.parameters())\n",
        "\n",
        "imagination = ImaginationCore(1, state_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=full_rollout)\n",
        "\n",
        "actor_critic = I2A(state_shape, num_actions, num_rewards, 256, imagination, full_rollout=full_rollout)\n",
        "#rmsprop hyperparams:\n",
        "lr    = 7e-4\n",
        "eps   = 1e-5\n",
        "alpha = 0.99\n",
        "optimizer = optim.RMSprop(actor_critic.parameters(), lr, eps=eps, alpha=alpha)\n",
        "\n",
        "\n",
        "if USE_CUDA:\n",
        "    env_model     = env_model.cuda()\n",
        "    distil_policy = distil_policy.cuda()\n",
        "    actor_critic  = actor_critic.cuda()"
      ],
      "metadata": {
        "id": "hAeM-I5V56JI"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "entropy_coef = 0.01\n",
        "value_loss_coef = 0.5\n",
        "max_grad_norm = 0.5\n",
        "num_steps = 5\n",
        "num_frames = int(10e5)\n",
        "\n",
        "rollout = RolloutStorage(num_steps, num_envs, envs.observation_space.shape)\n",
        "#rollout.cuda()\n",
        "\n",
        "all_rewards = []\n",
        "all_losses  = []"
      ],
      "metadata": {
        "id": "bL70kzgF59SL"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = envs.reset()\n",
        "current_state = torch.FloatTensor(np.float32(state))\n",
        "\n",
        "rollout.states[0].copy_(current_state)\n",
        "\n",
        "episode_rewards = torch.zeros(num_envs, 1)\n",
        "final_rewards   = torch.zeros(num_envs, 1)\n",
        "\n",
        "for i_update in range(num_frames):\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        if USE_CUDA:\n",
        "            current_state = current_state.cuda()\n",
        "        action = actor_critic.act(Variable(current_state))\n",
        "\n",
        "        next_state, reward, done, _ = envs.step(action.squeeze(1).cpu().data.numpy())\n",
        "\n",
        "        reward = torch.FloatTensor(reward).unsqueeze(1)\n",
        "        episode_rewards += reward\n",
        "        masks = torch.FloatTensor(1-np.array(done)).unsqueeze(1)\n",
        "        final_rewards *= masks\n",
        "        final_rewards += (1-masks) * episode_rewards\n",
        "        episode_rewards *= masks\n",
        "\n",
        "        if USE_CUDA:\n",
        "            masks = masks.cuda()\n",
        "\n",
        "        current_state = torch.FloatTensor(np.float32(next_state))\n",
        "        rollout.insert(step, current_state, action.data, reward, masks)\n",
        "\n",
        "\n",
        "    _, next_value = actor_critic(Variable(rollout.states[-1], volatile=True))\n",
        "    next_value = next_value.data\n",
        "\n",
        "    returns = rollout.compute_returns(next_value, gamma)\n",
        "\n",
        "    logit, action_log_probs, values, entropy = actor_critic.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_logit, _, _, _ = distil_policy.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_loss = 0.01 * (F.softmax(logit).detach() * F.log_softmax(distil_logit)).sum(1).mean()\n",
        "\n",
        "    values = values.view(num_steps, num_envs, 1)\n",
        "    action_log_probs = action_log_probs.view(num_steps, num_envs, 1)\n",
        "    advantages = Variable(returns) - values\n",
        "\n",
        "    value_loss = advantages.pow(2).mean()\n",
        "    action_loss = -(Variable(advantages.data) * action_log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = value_loss * value_loss_coef + action_loss - entropy * entropy_coef\n",
        "    loss.backward()\n",
        "    loss=loss.unsqueeze(0)\n",
        "    loss=loss.cpu()\n",
        "    nn.utils.clip_grad_norm(actor_critic.parameters(), max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    distil_optimizer.zero_grad()\n",
        "    distil_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i_update % 100 == 0:\n",
        "        all_rewards.append(final_rewards.mean())\n",
        "        all_losses.append(loss.data[0])\n",
        "        all_losses2 = torch.stack([loss.cpu() for loss in all_losses]).cpu()\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('epoch %s. reward: %s' % (i_update, np.mean(all_rewards[-10:])))\n",
        "        plt.plot(all_rewards)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss %s' % all_losses[-1])\n",
        "        plt.plot(all_losses2)\n",
        "        plt.show()\n",
        "\n",
        "    rollout.after_update()"
      ],
      "metadata": {
        "id": "B6E2eBbc6Cq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(actor_critic.state_dict(), \"i2a_\" + mode)"
      ],
      "metadata": {
        "id": "hQPCzcWz6D9t"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TXymnak5fN3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N0lru5JXfOrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep State Space Models\n",
        "The autoregressive models can be computationally expensive as they need to generate each previous state to generate the next state. An alternate model we found was the stochastic state space model. Here we assume that the next state is only dependent on the current state (memoryless states).\n",
        "This implementation is based on the paper- https://arxiv.org/pdf/1802.03006 (Learning and Querying Generative Models for RL)\n",
        "We also took reference from- https://github.com/davidsandberg/rl_ssms?tab=readme-ov-file which implements the model for a bouncing ball environment.\n",
        "\n",
        "We have edited the model to have the same type of input output as the original model, but a key difference is that this model does not need to calculate the exact state of the environment in each step but relies on learning from latent states."
      ],
      "metadata": {
        "id": "jJI4R46s1uai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class EnvModel2(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, horizon, nrof_init_time_steps=1, nrof_time_steps=1, nrof_free_nats=0.0):\n",
        "        super(EnvModel2, self).__init__()\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.horizon = horizon\n",
        "        self.nrof_init_time_steps = nrof_init_time_steps\n",
        "        self.nrof_time_steps = nrof_time_steps\n",
        "        self.nrof_free_nats = nrof_free_nats\n",
        "\n",
        "        # Encoder for the current state image\n",
        "        self.state_encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1280, state_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder for the next state image\n",
        "        self.state_decoder = nn.Sequential(\n",
        "            nn.Linear(state_dim, 1280),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 4, 5)),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Transition model\n",
        "        self.transition_model = nn.Sequential(\n",
        "            nn.Linear(state_dim + action_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, state_dim * 2)\n",
        "        )\n",
        "\n",
        "        # Observation model\n",
        "        self.observation_model = nn.Sequential(\n",
        "            nn.Linear(state_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, state_dim * 2)\n",
        "        )\n",
        "\n",
        "        # Imagination model\n",
        "        self.imagination_model = nn.GRUCell(state_dim + action_dim, state_dim)\n",
        "\n",
        "        # Reward model\n",
        "        self.reward_model = nn.Sequential(\n",
        "            nn.Linear(state_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs, actions):\n",
        "        batch_size = obs.shape[0]\n",
        "        imagined_actions=actions\n",
        "        # Encode observations\n",
        "        encoded_obs = self.state_encoder(obs)\n",
        "        #print(encoded_obs.shape)\n",
        "        # Initialize state\n",
        "        initial_state = encoded_obs.view(batch_size, self.nrof_init_time_steps, self.state_dim)\n",
        "        state = initial_state[:, -1, :]\n",
        "\n",
        "        # Convert actions to one-hot\n",
        "        onehot_actions = F.one_hot(actions.long(), num_classes=self.action_dim).float()\n",
        "        onehot_imagined_actions = F.one_hot(imagined_actions.long(), num_classes=self.action_dim).float()\n",
        "\n",
        "        obs_hat_list = []\n",
        "        next_state_list = []\n",
        "        reward_list = []\n",
        "\n",
        "        for t in range(self.nrof_time_steps):\n",
        "            # Compute prior statistics\n",
        "            #print(onehot_actions[:, :].shape)\n",
        "            mu, sigma = torch.split(self.transition_model(torch.cat([state, onehot_actions], dim=1)), self.state_dim, dim=-1)\n",
        "\n",
        "            # Compute posterior statistics\n",
        "            mu_hat, sigma_hat = torch.split(self.observation_model(state), self.state_dim, dim=-1)\n",
        "\n",
        "            # Sample from z using the reparametrization trick\n",
        "            eps = torch.randn_like(sigma)\n",
        "            z = mu + sigma * eps\n",
        "\n",
        "            # Calculate next state\n",
        "            z_trans = z\n",
        "            input_tensor = torch.cat([onehot_imagined_actions, state], dim=1)\n",
        "            next_state = self.imagination_model(input_tensor,z_trans)\n",
        "            #print(\"next state\",next_state.shape)\n",
        "            next_state_list.append(next_state)\n",
        "\n",
        "            # Calculate observation\n",
        "            z_obs = z.unsqueeze(1)\n",
        "            next_state_hat=self.state_decoder(next_state)\n",
        "            #print(next_state_hat.shape)\n",
        "            obs_hat = torch.sigmoid(self.state_encoder(next_state_hat))\n",
        "            obs_hat_list.append(obs_hat)\n",
        "\n",
        "            # Calculate reward\n",
        "            reward = self.reward_model(next_state)\n",
        "            reward_list.append(reward)\n",
        "\n",
        "            state = next_state.squeeze(1)\n",
        "\n",
        "        next_state = torch.stack(next_state_list, dim=-1)\n",
        "        #print(\"heyho\",next_state.shape)\n",
        "        obs_hat = torch.stack(obs_hat_list, dim=-1)[:,:,0]\n",
        "        #print(\"dimsum\",obs_hat.shape)\n",
        "        reward = torch.stack(reward_list, dim=-1)[:,:,0]\n",
        "\n",
        "        # Decode next state to image\n",
        "        next_state_img = self.state_decoder(next_state[:,:,0])\n",
        "\n",
        "        # Calculate loss\n",
        "        reconstruction_loss = F.binary_cross_entropy(obs_hat[:, self.nrof_init_time_steps:], torch.clamp(encoded_obs[:, self.nrof_init_time_steps:], 0, 1))\n",
        "\n",
        "        # Calculate regularization loss\n",
        "        f = self.nrof_free_nats * torch.prod(torch.tensor(mu.shape[2:]))\n",
        "        regularization_loss = torch.maximum(f, torch.sum(0.5 * (mu - mu_hat) ** 2 / sigma_hat ** 2 + 0.5 * sigma_hat ** 2, dim=-1))\n",
        "\n",
        "        return next_state_img, reward, obs_hat, reconstruction_loss, regularization_loss"
      ],
      "metadata": {
        "id": "5MMKCP0RvHw0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import Normal\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "reward_coef = 0.1\n",
        "num_updates = 5000\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n\n",
        "state_dim = 64\n",
        "action_dim = num_actions\n",
        "horizon = 10\n",
        "\n",
        "env_model = EnvModel2(state_dim, action_dim, horizon)\n",
        "actor_critic = ActorCritic(state_shape, action_dim)\n",
        "optimizer = optim.Adam(env_model.parameters(), lr=0.001)\n",
        "\n",
        "if USE_CUDA:\n",
        "    env_model = env_model.cuda()\n",
        "    actor_critic = actor_critic.cuda()\n",
        "\n",
        "actor_critic.load_state_dict(torch.load(\"actor_critic_\" + mode))\n",
        "def play_games(envs, frames):\n",
        "    states = envs.reset()\n",
        "    for frame_idx in range(frames):\n",
        "        actions = get_action(states)\n",
        "        next_states, rewards, dones, _ = envs.step(actions)\n",
        "        yield frame_idx, states, actions, rewards, next_states, dones\n",
        "        states = next_states\n",
        "\n",
        "def get_action(state):\n",
        "    if state.ndim == 4:\n",
        "        state = torch.FloatTensor(np.float32(state))\n",
        "    else:\n",
        "        state = torch.FloatTensor(np.float32(state)).unsqueeze(0)\n",
        "    if USE_CUDA:\n",
        "      state=state.cuda()\n",
        "    action = actor_critic.act(Variable(state, volatile=True))\n",
        "    action = action.data.cpu().squeeze(1).numpy()\n",
        "\n",
        "    return action\n",
        "\n",
        "optimizer = optim.Adam(env_model.parameters(), lr=0.001)\n",
        "\n",
        "for frame_idx, states, actions, rewards, next_states, dones in play_games(envs, num_updates):\n",
        "    states = torch.FloatTensor(states)\n",
        "    actions = torch.LongTensor(actions)\n",
        "    #imagined_actions = torch.LongTensor(actions)  # Assuming no separate imagined actions\n",
        "    batch_size = states.size(0)\n",
        "\n",
        "    if USE_CUDA:\n",
        "        states = states.cuda()\n",
        "        actions = actions.cuda()\n",
        "        imagined_actions = imagined_actions.cuda()\n",
        "\n",
        "    next_state_img, reward_pred, obs_hat, recon_loss, reg_loss = env_model(states, actions)\n",
        "    reward_pred=reward_pred.cpu()\n",
        "    optimizer.zero_grad()\n",
        "    loss = recon_loss + reward_coef * F.mse_loss(reward_pred.squeeze(), torch.FloatTensor(rewards).unsqueeze(1)) + reg_loss\n",
        "    loss = loss.mean()\n",
        "    optimizer.step()\n",
        "\n",
        "    if frame_idx % 10 == 0:\n",
        "        print(f\"Frame: {frame_idx}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "wC3lNhr_vI6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(env_model.state_dict(), \"env_model2_\" + mode)"
      ],
      "metadata": {
        "id": "qr0P_a28B_39"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE as an Environment Model\n",
        "This is an implementation of Variational Autoencoders as an environment model. They are more computationally effecient that both of the previous two models.They also use latent states to learn about the actual state without directly computing the state.\n",
        "Inspiration for this was drawn from- https://worldmodels.github.io/"
      ],
      "metadata": {
        "id": "pG30p-fYCAfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Normal\n",
        "\n",
        "class PacmanVAE(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, horizon):\n",
        "        super(PacmanVAE, self).__init__()\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.horizon = horizon\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(8, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 3, 512),  # Adjusted input size\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, state_dim * 2)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(state_dim + action_dim, 64 * 4 * 5),  # Adjusted input size\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (64, 4, 5)),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # Reward model\n",
        "        self.reward_model = nn.Sequential(\n",
        "            nn.Linear(state_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        batch_size = state.size(0)\n",
        "\n",
        "        # Encode state\n",
        "        mu, logvar = torch.split(self.encoder(torch.cat([state, action], dim=1)), self.state_dim, dim=-1)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        # Decode next state\n",
        "        actions1 = action[:, :, 0, 0]\n",
        "        next_state = self.decoder(torch.cat([z, actions1], dim=-1))\n",
        "        next_state = next_state[:, :, :15, :19]\n",
        "        # Compute reward\n",
        "        reward = self.reward_model(z)\n",
        "\n",
        "        return next_state, reward, mu, logvar"
      ],
      "metadata": {
        "id": "2brSVtK4CD3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n\n",
        "state_dim = 64\n",
        "action_dim = num_actions\n",
        "horizon = 10\n",
        "\n",
        "vae_model = PacmanVAE(state_dim, action_dim, horizon)\n",
        "optimizer = optim.Adam(vae_model.parameters(), lr=0.001)\n",
        "actor_critic = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "\n",
        "if USE_CUDA:\n",
        "    vae_model = vae_model.cuda()\n",
        "    actor_critic = actor_critic.cuda()\n",
        "\n",
        "actor_critic.load_state_dict(torch.load(\"actor_critic_\" + mode))\n",
        "def get_action(state):\n",
        "    if state.ndim == 4:\n",
        "        state = torch.FloatTensor(np.float32(state))\n",
        "    else:\n",
        "        state = torch.FloatTensor(np.float32(state)).unsqueeze(0)\n",
        "    if USE_CUDA:\n",
        "      state=state.cuda()\n",
        "    '''if state.ndim!=4:\n",
        "      state=state.unsqueeze(0)'''\n",
        "\n",
        "    action = actor_critic.act(Variable(state, volatile=True))\n",
        "    action = action.data.cpu().squeeze(1).numpy()\n",
        "    return action\n",
        "\n",
        "\n",
        "def play_games(envs, frames):\n",
        "    states = envs.reset()\n",
        "\n",
        "    for frame_idx in range(frames):\n",
        "        action = get_action(states)\n",
        "        next_states, rewards, dones, _ = envs.step(action)\n",
        "        yield frame_idx, state.cpu(), action, rewards, next_states, dones\n",
        "        states = next_states\n",
        "\n",
        "num_updates = 5000\n",
        "beta = 1.0  # Weight for the KL divergence term\n",
        "\n",
        "for frame_idx, state, action, rewards, next_states, dones in play_games(envs, num_updates):\n",
        "    state = torch.FloatTensor(state)\n",
        "    next_state = torch.FloatTensor(next_states)\n",
        "    action     = torch.LongTensor(action)\n",
        "    batch_size = state.size(0)\n",
        "\n",
        "    onehot_actions = torch.zeros(batch_size, num_actions, *state_shape[1:])\n",
        "    onehot_actions[range(batch_size), action] = 1\n",
        "\n",
        "    if USE_CUDA:\n",
        "        state = state.cuda()\n",
        "        onehot_actions = onehot_actions.cuda()\n",
        "        next_state = next_state.cuda()\n",
        "\n",
        "    next_state_pred, reward_pred, mu, logvar = vae_model(state, onehot_actions)\n",
        "    reward_pred=reward_pred.cpu()\n",
        "    #print(next_state_pred.shape)\n",
        "    #print(next_state.shape)\n",
        "    recon_loss = F.mse_loss(next_state_pred, next_state, reduction='sum')\n",
        "    reward_loss = F.mse_loss(reward_pred.squeeze(), torch.FloatTensor(rewards).unsqueeze(1), reduction='sum')\n",
        "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    loss = recon_loss + reward_loss + beta * kl_loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if frame_idx % 100 == 0:\n",
        "        print(f\"Frame: {frame_idx}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "id": "t7u5dkopFmKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vae_model.state_dict(), \"vae_model_\" + mode)"
      ],
      "metadata": {
        "id": "ggpP4zfAF674"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using I2A with deep state space model\n",
        "Note- due to time and resource constraint this section is not working as well. Nevertheless I am including it for completeness of the experiment."
      ],
      "metadata": {
        "id": "vZn0cqg1CVDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA=False\n",
        "pixels = (\n",
        "    (0.0, 1.0, 0.0),\n",
        "    (0.0, 1.0, 1.0),\n",
        "    (0.0, 0.0, 1.0),\n",
        "    (1.0, 1.0, 1.0),\n",
        "    (1.0, 1.0, 0.0),\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (1.0, 0.0, 0.0)\n",
        ")\n",
        "pixel_to_onehot = {pix:i for i, pix in enumerate(pixels)}\n",
        "num_pixels = len(pixels)\n",
        "\n",
        "task_rewards = {\n",
        "    \"regular\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"avoid\":   [0.1, -0.1, -5, -10, -20],\n",
        "    \"hunt\":    [0, 1, 10, -20],\n",
        "    \"ambush\":  [0, -0.1, 10, -20],\n",
        "    \"rush\":    [0, -0.1, 9.9]\n",
        "}\n",
        "reward_to_onehot = {mode: {reward:i for i, reward in enumerate(task_rewards[mode])} for mode in task_rewards.keys()}\n",
        "\n",
        "def pix_to_target(next_states):\n",
        "    target = []\n",
        "    for pixel in next_states.transpose(0, 2, 3, 1).reshape(-1, 3):\n",
        "        target.append(pixel_to_onehot[tuple([np.round(pixel[0]), np.round(pixel[1]), np.round(pixel[2])])])\n",
        "    return target\n",
        "\n",
        "def target_to_pix(imagined_states):\n",
        "    pixels = []\n",
        "    to_pixel = {value: key for key, value in pixel_to_onehot.items()}\n",
        "    for target in imagined_states:\n",
        "        pixels.append(list(to_pixel[target]))\n",
        "    return np.array(pixels)\n",
        "\n",
        "def rewards_to_target(mode, rewards):\n",
        "    target = []\n",
        "    for reward in rewards:\n",
        "        target.append(reward_to_onehot[mode][reward])\n",
        "    return target\n",
        "\n",
        "def displayImage(image, step, reward):\n",
        "    s = str(step) + \" \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n\n",
        "num_rewards = len(task_rewards[mode])\n",
        "full_rollout = True"
      ],
      "metadata": {
        "id": "9tzu5uYWDyFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we edit the Imagination core to support the deep state space model. Not much modification was needed except the input output types."
      ],
      "metadata": {
        "id": "puaxvjLYsINa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImaginationCore(object):\n",
        "    def __init__(self, num_rolouts, in_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=True):\n",
        "        self.num_rolouts  = num_rolouts\n",
        "        self.in_shape      = in_shape\n",
        "        self.num_actions   = num_actions\n",
        "        self.num_rewards   = num_rewards\n",
        "        self.env_model     = env_model\n",
        "        self.distil_policy = distil_policy\n",
        "        self.full_rollout  = full_rollout\n",
        "\n",
        "    def __call__(self, state):\n",
        "        state      = state.cpu()\n",
        "        batch_size = state.size(0)\n",
        "\n",
        "        rollout_states  = []\n",
        "        rollout_rewards = []\n",
        "\n",
        "        if self.full_rollout:\n",
        "            state = state.unsqueeze(0).repeat(self.num_actions, 1, 1, 1, 1).view(-1, *self.in_shape)\n",
        "            action = torch.LongTensor([[i] for i in range(self.num_actions)]*batch_size)\n",
        "            action = action.view(-1)\n",
        "            rollout_batch_size = batch_size * self.num_actions\n",
        "        else:\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "            rollout_batch_size = batch_size\n",
        "\n",
        "        for step in range(self.num_rolouts):\n",
        "            onehot_action = torch.zeros(rollout_batch_size, self.num_actions, *self.in_shape[1:])\n",
        "            onehot_action[range(rollout_batch_size), action] = 1\n",
        "            inputs = torch.cat([state, onehot_action], 1)\n",
        "\n",
        "            imagined_state, imagined_reward = self.env_model(state,onehot_action)\n",
        "\n",
        "            imagined_state  = F.softmax(imagined_state).max(1)[1].data.cpu()\n",
        "            imagined_reward = F.softmax(imagined_reward).max(1)[1].data.cpu()\n",
        "\n",
        "            imagined_state = target_to_pix(imagined_state.numpy())\n",
        "            imagined_state = torch.FloatTensor(imagined_state).view(rollout_batch_size, *self.in_shape)\n",
        "\n",
        "            onehot_reward = torch.zeros(rollout_batch_size, self.num_rewards)\n",
        "            onehot_reward[range(rollout_batch_size), imagined_reward] = 1\n",
        "\n",
        "            rollout_states.append(imagined_state.unsqueeze(0))\n",
        "            rollout_rewards.append(onehot_reward.unsqueeze(0))\n",
        "\n",
        "            state  = imagined_state\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "\n",
        "        return torch.cat(rollout_states), torch.cat(rollout_rewards)"
      ],
      "metadata": {
        "id": "dZbrek0sFKuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dim = 64\n",
        "action_dim = num_actions\n",
        "horizon = 10\n",
        "env_model = EnvModel2(state_dim,action_dim,horizon)\n",
        "env_model.load_state_dict(torch.load(\"env_model2_\" + mode))\n",
        "\n",
        "distil_policy = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "distil_optimizer = optim.Adam(distil_policy.parameters())\n",
        "\n",
        "imagination = ImaginationCore(1, state_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=full_rollout)\n",
        "\n",
        "actor_critic = I2A(state_shape, num_actions, num_rewards, 256, imagination, full_rollout=full_rollout)\n",
        "#rmsprop hyperparams:\n",
        "lr    = 7e-4\n",
        "eps   = 1e-5\n",
        "alpha = 0.99\n",
        "optimizer = optim.RMSprop(actor_critic.parameters(), lr, eps=eps, alpha=alpha)\n",
        "\n",
        "\n",
        "if USE_CUDA:\n",
        "    env_model     = env_model.cuda()\n",
        "    distil_policy = distil_policy.cuda()\n",
        "    actor_critic  = actor_critic.cuda()"
      ],
      "metadata": {
        "id": "vNDVcWJpCZIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "entropy_coef = 0.01\n",
        "value_loss_coef = 0.5\n",
        "max_grad_norm = 0.5\n",
        "num_steps = 5\n",
        "num_frames = int(10e5)\n",
        "\n",
        "rollout = RolloutStorage(num_steps, num_envs, envs.observation_space.shape)\n",
        "rollout.cuda()\n",
        "\n",
        "all_rewards = []\n",
        "all_losses  = []"
      ],
      "metadata": {
        "id": "V9PrRZE2DSlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = envs.reset()\n",
        "current_state = torch.FloatTensor(np.float32(state))\n",
        "\n",
        "rollout.states[0].copy_(current_state)\n",
        "\n",
        "episode_rewards = torch.zeros(num_envs, 1)\n",
        "final_rewards   = torch.zeros(num_envs, 1)\n",
        "\n",
        "for i_update in range(num_frames):\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        if USE_CUDA:\n",
        "            current_state = current_state.cuda()\n",
        "        action = actor_critic.act(Variable(current_state))\n",
        "\n",
        "        next_state, reward, done, _ = envs.step(action.squeeze(1).cpu().data.numpy())\n",
        "\n",
        "        reward = torch.FloatTensor(reward).unsqueeze(1)\n",
        "        episode_rewards += reward\n",
        "        masks = torch.FloatTensor(1-np.array(done)).unsqueeze(1)\n",
        "        final_rewards *= masks\n",
        "        final_rewards += (1-masks) * episode_rewards\n",
        "        episode_rewards *= masks\n",
        "\n",
        "        if USE_CUDA:\n",
        "            masks = masks.cuda()\n",
        "\n",
        "        current_state = torch.FloatTensor(np.float32(next_state))\n",
        "        rollout.insert(step, current_state, action.data, reward, masks)\n",
        "\n",
        "\n",
        "    _, next_value = actor_critic(Variable(rollout.states[-1], volatile=True))\n",
        "    next_value = next_value.data\n",
        "\n",
        "    returns = rollout.compute_returns(next_value, gamma)\n",
        "\n",
        "    logit, action_log_probs, values, entropy = actor_critic.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_logit, _, _, _ = distil_policy.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_loss = 0.01 * (F.softmax(logit).detach() * F.log_softmax(distil_logit)).sum(1).mean()\n",
        "\n",
        "    values = values.view(num_steps, num_envs, 1)\n",
        "    action_log_probs = action_log_probs.view(num_steps, num_envs, 1)\n",
        "    advantages = Variable(returns) - values\n",
        "\n",
        "    value_loss = advantages.pow(2).mean()\n",
        "    action_loss = -(Variable(advantages.data) * action_log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = value_loss * value_loss_coef + action_loss - entropy * entropy_coef\n",
        "    loss.backward()\n",
        "    loss=loss.unsqueeze(0)\n",
        "    loss=loss.cpu()\n",
        "    nn.utils.clip_grad_norm(actor_critic.parameters(), max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    distil_optimizer.zero_grad()\n",
        "    distil_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i_update % 100 == 0:\n",
        "        all_rewards.append(final_rewards.mean())\n",
        "        all_losses.append(loss.data[0])\n",
        "        all_losses2 = torch.stack([loss.cpu() for loss in all_losses]).cpu()\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('epoch %s. reward: %s' % (i_update, np.mean(all_rewards[-10:])))\n",
        "        plt.plot(all_rewards)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss %s' % all_losses[-1])\n",
        "        plt.plot(all_losses2)\n",
        "        plt.show()\n",
        "\n",
        "    rollout.after_update()"
      ],
      "metadata": {
        "id": "GRdwQD75DZgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.save(actor_critic.state_dict(), \"i2a_\" + mode)"
      ],
      "metadata": {
        "id": "UFuRHjRZDb7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I2A with VAE model\n",
        "Note- due to time and resource constraint this section is not working as well. Nevertheless I am including it for completeness of the experiment."
      ],
      "metadata": {
        "id": "bNf1MCvjF7QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA=False\n",
        "pixels = (\n",
        "    (0.0, 1.0, 0.0),\n",
        "    (0.0, 1.0, 1.0),\n",
        "    (0.0, 0.0, 1.0),\n",
        "    (1.0, 1.0, 1.0),\n",
        "    (1.0, 1.0, 0.0),\n",
        "    (0.0, 0.0, 0.0),\n",
        "    (1.0, 0.0, 0.0)\n",
        ")\n",
        "pixel_to_onehot = {pix:i for i, pix in enumerate(pixels)}\n",
        "num_pixels = len(pixels)\n",
        "\n",
        "task_rewards = {\n",
        "    \"regular\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
        "    \"avoid\":   [0.1, -0.1, -5, -10, -20],\n",
        "    \"hunt\":    [0, 1, 10, -20],\n",
        "    \"ambush\":  [0, -0.1, 10, -20],\n",
        "    \"rush\":    [0, -0.1, 9.9]\n",
        "}\n",
        "reward_to_onehot = {mode: {reward:i for i, reward in enumerate(task_rewards[mode])} for mode in task_rewards.keys()}\n",
        "\n",
        "def pix_to_target(next_states):\n",
        "    target = []\n",
        "    for pixel in next_states.transpose(0, 2, 3, 1).reshape(-1, 3):\n",
        "        target.append(pixel_to_onehot[tuple([np.round(pixel[0]), np.round(pixel[1]), np.round(pixel[2])])])\n",
        "    return target\n",
        "\n",
        "def target_to_pix(imagined_states):\n",
        "    pixels = []\n",
        "    to_pixel = {value: key for key, value in pixel_to_onehot.items()}\n",
        "    for target in imagined_states:\n",
        "        print(target)\n",
        "        pixels.append(list(to_pixel[target]))\n",
        "    return np.array(pixels)\n",
        "\n",
        "def rewards_to_target(mode, rewards):\n",
        "    target = []\n",
        "    for reward in rewards:\n",
        "        target.append(reward_to_onehot[mode][reward])\n",
        "    return target\n",
        "\n",
        "def displayImage(image, step, reward):\n",
        "    s = str(step) + \" \" + str(reward)\n",
        "    plt.title(s)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "mode = \"regular\"\n",
        "num_envs = 16\n",
        "\n",
        "def make_env():\n",
        "    def _thunk():\n",
        "        env = MiniPacman(mode, 1000)\n",
        "        return env\n",
        "\n",
        "    return _thunk\n",
        "\n",
        "envs = [make_env() for i in range(num_envs)]\n",
        "envs = SubprocVecEnv(envs)\n",
        "\n",
        "state_shape = envs.observation_space.shape\n",
        "num_actions = envs.action_space.n\n",
        "num_rewards = len(task_rewards[mode])\n",
        "full_rollout=True\n",
        "state_dim = 64\n",
        "action_dim = num_actions\n",
        "horizon = 10"
      ],
      "metadata": {
        "id": "tnSHZJ3pF-_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImaginationCoreVAE(object):\n",
        "    def __init__(self, num_rolouts, in_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=True):\n",
        "        self.num_rolouts  = num_rolouts\n",
        "        self.in_shape      = in_shape\n",
        "        self.num_actions   = num_actions\n",
        "        self.num_rewards   = num_rewards\n",
        "        self.env_model     = env_model\n",
        "        self.distil_policy = distil_policy\n",
        "        self.full_rollout  = full_rollout\n",
        "\n",
        "    def __call__(self, state):\n",
        "        state      = state.cpu()\n",
        "        batch_size = state.size(0)\n",
        "\n",
        "        rollout_states  = []\n",
        "        rollout_rewards = []\n",
        "\n",
        "        if self.full_rollout:\n",
        "            state = state.unsqueeze(0).repeat(self.num_actions, 1, 1, 1, 1).view(-1, *self.in_shape)\n",
        "            action = torch.LongTensor([[i] for i in range(self.num_actions)]*batch_size)\n",
        "            action = action.view(-1)\n",
        "            rollout_batch_size = batch_size * self.num_actions\n",
        "        else:\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "            rollout_batch_size = batch_size\n",
        "\n",
        "        for step in range(self.num_rolouts):\n",
        "            onehot_action = torch.zeros(rollout_batch_size, self.num_actions, *self.in_shape[1:])\n",
        "            onehot_action[range(rollout_batch_size), action] = 1\n",
        "            #inputs = torch.cat([state, onehot_action], 1)\n",
        "\n",
        "            imagined_state, imagined_reward,_,_ = self.env_model(state,onehot_action)\n",
        "\n",
        "            #imagined_state  = F.softmax(imagined_state).max(1)[1].data.cpu()\n",
        "            imagined_reward = F.softmax(imagined_reward).max(1)[1].data.cpu()\n",
        "            #print(type(imagined_state))\n",
        "            #imagined_state = target_to_pix(imagined_state.numpy())\n",
        "            imagined_state = torch.FloatTensor(imagined_state).view(rollout_batch_size, *self.in_shape)\n",
        "\n",
        "            onehot_reward = torch.zeros(rollout_batch_size, self.num_rewards)\n",
        "            onehot_reward[range(rollout_batch_size), imagined_reward] = 1\n",
        "\n",
        "            rollout_states.append(imagined_state.unsqueeze(0))\n",
        "            rollout_rewards.append(onehot_reward.unsqueeze(0))\n",
        "\n",
        "            state  = imagined_state\n",
        "            action = self.distil_policy.act(Variable(state, volatile=True))\n",
        "            action = action.data.cpu()\n",
        "\n",
        "        return torch.cat(rollout_states), torch.cat(rollout_rewards)"
      ],
      "metadata": {
        "id": "SzQ6CzefHUFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_model     = PacmanVAE(state_dim, action_dim, horizon)\n",
        "env_model.load_state_dict(torch.load(\"vae_model_\" + mode))\n",
        "\n",
        "distil_policy = ActorCritic(envs.observation_space.shape, envs.action_space.n)\n",
        "distil_optimizer = optim.Adam(distil_policy.parameters())\n",
        "\n",
        "imagination = ImaginationCoreVAE(1, state_shape, num_actions, num_rewards, env_model, distil_policy, full_rollout=full_rollout)\n",
        "\n",
        "actor_critic = I2A(state_shape, num_actions, num_rewards, 256, imagination, full_rollout=full_rollout)\n",
        "#rmsprop hyperparams:\n",
        "lr    = 7e-4\n",
        "eps   = 1e-5\n",
        "alpha = 0.99\n",
        "optimizer = optim.RMSprop(actor_critic.parameters(), lr, eps=eps, alpha=alpha)\n",
        "\n",
        "\n",
        "if USE_CUDA:\n",
        "    env_model     = env_model.cuda()\n",
        "    distil_policy = distil_policy.cuda()\n",
        "    actor_critic  = actor_critic.cuda()"
      ],
      "metadata": {
        "id": "uzf-Wo1LGUFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "entropy_coef = 0.01\n",
        "value_loss_coef = 0.5\n",
        "max_grad_norm = 0.5\n",
        "num_steps = 5\n",
        "num_frames = int(10e5)\n",
        "\n",
        "rollout = RolloutStorage(num_steps, num_envs, envs.observation_space.shape)\n",
        "rollout.cuda()\n",
        "\n",
        "all_rewards = []\n",
        "all_losses  = []"
      ],
      "metadata": {
        "id": "GZQR1NP5Gbr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = envs.reset()\n",
        "current_state = torch.FloatTensor(np.float32(state))\n",
        "\n",
        "rollout.states[0].copy_(current_state)\n",
        "\n",
        "episode_rewards = torch.zeros(num_envs, 1)\n",
        "final_rewards   = torch.zeros(num_envs, 1)\n",
        "\n",
        "for i_update in range(num_frames):\n",
        "\n",
        "    for step in range(num_steps):\n",
        "        if USE_CUDA:\n",
        "            current_state = current_state.cuda()\n",
        "        action = actor_critic.act(Variable(current_state))\n",
        "\n",
        "        next_state, reward, done, _ = envs.step(action.squeeze(1).cpu().data.numpy())\n",
        "\n",
        "        reward = torch.FloatTensor(reward).unsqueeze(1)\n",
        "        episode_rewards += reward\n",
        "        masks = torch.FloatTensor(1-np.array(done)).unsqueeze(1)\n",
        "        final_rewards *= masks\n",
        "        final_rewards += (1-masks) * episode_rewards\n",
        "        episode_rewards *= masks\n",
        "\n",
        "        if USE_CUDA:\n",
        "            masks = masks.cuda()\n",
        "\n",
        "        current_state = torch.FloatTensor(np.float32(next_state))\n",
        "        rollout.insert(step, current_state, action.data, reward, masks)\n",
        "\n",
        "\n",
        "    _, next_value = actor_critic(Variable(rollout.states[-1], volatile=True))\n",
        "    next_value = next_value.data\n",
        "\n",
        "    returns = rollout.compute_returns(next_value, gamma)\n",
        "\n",
        "    logit, action_log_probs, values, entropy = actor_critic.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_logit, _, _, _ = distil_policy.evaluate_actions(\n",
        "        Variable(rollout.states[:-1]).view(-1, *state_shape),\n",
        "        Variable(rollout.actions).view(-1, 1)\n",
        "    )\n",
        "\n",
        "    distil_loss = 0.01 * (F.softmax(logit).detach() * F.log_softmax(distil_logit)).sum(1).mean()\n",
        "\n",
        "    values = values.view(num_steps, num_envs, 1)\n",
        "    action_log_probs = action_log_probs.view(num_steps, num_envs, 1)\n",
        "    advantages = Variable(returns) - values\n",
        "\n",
        "    value_loss = advantages.pow(2).mean()\n",
        "    action_loss = -(Variable(advantages.data) * action_log_probs).mean()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = value_loss * value_loss_coef + action_loss - entropy * entropy_coef\n",
        "    loss.backward()\n",
        "    loss=loss.unsqueeze(0)\n",
        "    loss=loss.cpu()\n",
        "    nn.utils.clip_grad_norm(actor_critic.parameters(), max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "    distil_optimizer.zero_grad()\n",
        "    distil_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i_update % 100 == 0:\n",
        "        all_rewards.append(final_rewards.mean())\n",
        "        all_losses.append(loss.data[0])\n",
        "        all_losses2 = torch.stack([loss.cpu() for loss in all_losses]).cpu()\n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(20,5))\n",
        "        plt.subplot(131)\n",
        "        plt.title('epoch %s. reward: %s' % (i_update, np.mean(all_rewards[-10:])))\n",
        "        plt.plot(all_rewards)\n",
        "        plt.subplot(132)\n",
        "        plt.title('loss %s' % all_losses[-1])\n",
        "        plt.plot(all_losses2)\n",
        "        plt.show()\n",
        "\n",
        "    rollout.after_update()"
      ],
      "metadata": {
        "id": "By9Q4IKyGhgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "The main focus in designing environment models for the I2A architecture is the fact that it can learn better from imperfect models than perfect environment models. This means that abstract representations of the environment might prove more effecient for the Imagination core of a I2A than directly simulating the environment."
      ],
      "metadata": {
        "id": "Cga402txuS_6"
      }
    }
  ]
}
